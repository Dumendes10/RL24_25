{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "196716c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation shape: (210, 160, 3)\n",
      "Observation data type: uint8\n",
      "Action space: Discrete(6)\n",
      "\n",
      "--- Round 1 ---\n",
      "Step: 1, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 3, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 4, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 5, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 6, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 7, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 8, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 9, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 10, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 11, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 12, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 13, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 14, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 15, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 16, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 17, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 18, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 19, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 20, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 21, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 22, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 23, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 24, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 25, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 26, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 27, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 28, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 29, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 30, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 31, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 32, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 33, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 34, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 35, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 36, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 37, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 38, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 39, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 40, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 41, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 42, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 43, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 44, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 45, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 46, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 47, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 48, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 49, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 50, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 51, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 52, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 53, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 54, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 55, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 56, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 57, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 58, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 59, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 60, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 61, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 62, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 63, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 64, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 65, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 66, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 67, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 68, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 69, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 70, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 71, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 72, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 73, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 74, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 75, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 76, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 77, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 78, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 79, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 80, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 81, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 82, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 83, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 84, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 85, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 86, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 87, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 88, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 89, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 90, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 91, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 92, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 93, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 94, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 95, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 96, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 97, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 98, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 99, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 100, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 101, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 102, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 103, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 104, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 105, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 106, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 107, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 108, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 109, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 110, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 111, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 112, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 113, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 114, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 115, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 116, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 117, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 118, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 119, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 120, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 121, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 122, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 123, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 124, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 125, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 126, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 127, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 128, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 129, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 130, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 131, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 132, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 133, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 134, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 135, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 136, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 137, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 138, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 139, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 140, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 141, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 142, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 143, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 144, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 145, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 146, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 147, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 148, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 149, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 150, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 151, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 152, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 153, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 154, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 155, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 156, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 157, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 158, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 159, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 160, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 161, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 162, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 163, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 164, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 165, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 166, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 167, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 168, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 169, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 170, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 171, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 172, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 173, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 174, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 175, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 176, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 177, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 178, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 179, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 180, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 181, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 182, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 183, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 184, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 185, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 186, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 187, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 188, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 189, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 190, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 191, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 192, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 193, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 194, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 195, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 196, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 197, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 198, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 199, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 200, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 201, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 202, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 203, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 204, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 205, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 206, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 207, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 208, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 209, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 210, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 211, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 212, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 213, Action: 3, Reward: 3.0, Terminated: False, Truncated: False\n",
      "Step: 214, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 215, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 216, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 217, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 218, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 219, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 220, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 221, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 222, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 223, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 224, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 225, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 226, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 227, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 228, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 229, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 230, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 231, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 232, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 233, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 234, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 235, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 236, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 237, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 238, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 239, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 240, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 241, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 242, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 243, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 244, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 245, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 246, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 247, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 248, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 249, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 250, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 251, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 252, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 253, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 254, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 255, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 256, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 257, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 258, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 259, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 260, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 261, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 262, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 263, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 264, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 265, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 266, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 267, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 268, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 269, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 270, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 271, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 272, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 273, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 274, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 275, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 276, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 277, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 278, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 279, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 280, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 281, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 282, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 283, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 284, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 285, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 286, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 287, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 288, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 289, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 290, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 291, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 292, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 293, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 294, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 295, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 296, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 297, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 298, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 299, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 300, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 301, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 302, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 303, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 304, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 305, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 306, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 307, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 308, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 309, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 310, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 311, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 312, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 313, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 314, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 315, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 316, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 317, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 318, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 319, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 320, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 321, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 322, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 323, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 324, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 325, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 326, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 327, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 328, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 329, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 330, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 331, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 332, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 333, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 334, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 335, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 336, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 337, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 338, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 339, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 340, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 341, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 342, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 343, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 344, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 345, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 346, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 347, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 348, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 349, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 350, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 351, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 352, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 353, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 354, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 355, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 356, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 357, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 358, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 359, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 360, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 361, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 362, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 363, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 364, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 365, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 366, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 367, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 368, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 369, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 370, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 371, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 372, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 373, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 374, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 375, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 376, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 377, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 378, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 379, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 380, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 381, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 382, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 383, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 384, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 385, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 386, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 387, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 388, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 389, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 390, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 391, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 392, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 393, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 394, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 395, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 396, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 397, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 398, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 399, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 400, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 401, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 402, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 403, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 404, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 405, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 406, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 407, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 408, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 409, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 410, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 411, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 412, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 413, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 414, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 415, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 416, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 417, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 418, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 419, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 420, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 421, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 422, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 423, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 424, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 425, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 426, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 427, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 428, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 429, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 430, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 431, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 432, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 433, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 434, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 435, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 436, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 437, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 438, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 439, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 440, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 441, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 442, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 443, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 444, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 445, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 446, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 447, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 448, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 449, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 450, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 451, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 452, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 453, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 454, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 455, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 456, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 457, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 458, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 459, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 460, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 461, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 462, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 463, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 464, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 465, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 466, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 467, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 468, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 469, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 470, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 471, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 472, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 473, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 474, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 475, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 476, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 477, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 478, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 479, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 480, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 481, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 482, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 483, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 484, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 485, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 486, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 487, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 488, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 489, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 490, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 491, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 492, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 493, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 494, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 495, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 496, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 497, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 498, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 499, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 500, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 501, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 502, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 503, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 504, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 505, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 506, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 507, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 508, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 509, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 510, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 511, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 512, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 513, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 514, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 515, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 516, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 517, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 518, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 519, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 520, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 521, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 522, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 523, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 524, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 525, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 526, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 527, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 528, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 529, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 530, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 531, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 532, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 533, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 534, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 535, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 536, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 537, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 538, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 539, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 540, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 541, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 542, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 543, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 544, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 545, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 546, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 547, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 548, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 549, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 550, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 551, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 552, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 553, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 554, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 555, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 556, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 557, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 558, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 559, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 560, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 561, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 562, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 563, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 564, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 565, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 566, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 567, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 568, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 569, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 570, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 571, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 572, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 573, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 574, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 575, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 576, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 577, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 578, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 579, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 580, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 581, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 582, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 583, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 584, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 585, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 586, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 587, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 588, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 589, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 590, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 591, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 592, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 593, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 594, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 595, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 596, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 597, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 598, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 599, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 600, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 601, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 602, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 603, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 604, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 605, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 606, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 607, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 608, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 609, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 610, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 611, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 612, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 613, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 614, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 615, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 616, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 617, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 618, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 619, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 620, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 621, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 622, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 623, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 624, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 625, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 626, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 627, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 628, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 629, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 630, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 631, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 632, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 633, Action: 4, Reward: 1.0, Terminated: False, Truncated: False\n",
      "Step: 634, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 635, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 636, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 637, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 638, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 639, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 640, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 641, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 642, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 643, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 644, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 645, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 646, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 647, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 648, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 649, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 650, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 651, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 652, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 653, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 654, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 655, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 656, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 657, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 658, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 659, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 660, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 661, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 662, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 663, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 664, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 665, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 666, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 667, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 668, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 669, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 670, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 671, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 672, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 673, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 674, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 675, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 676, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 677, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 678, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 679, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 680, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 681, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 682, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 683, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 684, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 685, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 686, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 687, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 688, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 689, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 690, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 691, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 692, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 693, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 694, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 695, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 696, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 697, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 698, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 699, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 700, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 701, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 702, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 703, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 704, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 705, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 706, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 707, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 708, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 709, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 710, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 711, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 712, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 713, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 714, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 715, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 716, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 717, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 718, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 719, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 720, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 721, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 722, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 723, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 724, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 725, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 726, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 727, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 728, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 729, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 730, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 731, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 732, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 733, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 734, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 735, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 736, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 737, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 738, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 739, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 740, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 741, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 742, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 743, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 744, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 745, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 746, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 747, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 748, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 749, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 750, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 751, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 752, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 753, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 754, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 755, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 756, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 757, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 758, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 759, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 760, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 761, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 762, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 763, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 764, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 765, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 766, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 767, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 768, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 769, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 770, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 771, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 772, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 773, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 774, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 775, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 776, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 777, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 778, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 779, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 780, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 781, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 782, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 783, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 784, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 785, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 786, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 787, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 788, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 789, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 790, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 791, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 792, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 793, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 794, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 795, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 796, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 797, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 798, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 799, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 800, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 801, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 802, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 803, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 804, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 805, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 806, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 807, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 808, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 809, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 810, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 811, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 812, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 813, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 814, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 815, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 816, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 817, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 818, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 819, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 820, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 821, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 822, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 823, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 824, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 825, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 826, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 827, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 828, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 829, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 830, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 831, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 832, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 833, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 834, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 835, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 836, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 837, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 838, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 839, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 840, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 841, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 842, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 843, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 844, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 845, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 846, Action: 0, Reward: 3.0, Terminated: False, Truncated: False\n",
      "Step: 847, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 848, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 849, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 850, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 851, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 852, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 853, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 854, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 855, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 856, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 857, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 858, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 859, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 860, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 861, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 862, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 863, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 864, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 865, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 866, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 867, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 868, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 869, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 870, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 871, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 872, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 873, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 874, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 875, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 876, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 877, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 878, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 879, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 880, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 881, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 882, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 883, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 884, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 885, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 886, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 887, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 888, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 889, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 890, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 891, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 892, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 893, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 894, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 895, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 896, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 897, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 898, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 899, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 900, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 901, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 902, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 903, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 904, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 905, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 906, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 907, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 908, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 909, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 910, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 911, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 912, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 913, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 914, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 915, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 916, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 917, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 918, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 919, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 920, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 921, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 922, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 923, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 924, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 925, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 926, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 927, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 928, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 929, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 930, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 931, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 932, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 933, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 934, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 935, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 936, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 937, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 938, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 939, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 940, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 941, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 942, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 943, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 944, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 945, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 946, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 947, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 948, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 949, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 950, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 951, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 952, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 953, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 954, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 955, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 956, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 957, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 958, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 959, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 960, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 961, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 962, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 963, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 964, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 965, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 966, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 967, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 968, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 969, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 970, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 971, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 972, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 973, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 974, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 975, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 976, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 977, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 978, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 979, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 980, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 981, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 982, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 983, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 984, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 985, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 986, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 987, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 988, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 989, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 990, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 991, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 992, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 993, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 994, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 995, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 996, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 997, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 998, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 999, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1000, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1001, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1002, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1003, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1004, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1005, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1006, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1007, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1008, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1009, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1010, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1011, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1012, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1013, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1014, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1015, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1016, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1017, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1018, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1019, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1020, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1021, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1022, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1023, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1024, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1025, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1026, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1027, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1028, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1029, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1030, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1031, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1032, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1033, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1034, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1035, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1036, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1037, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1038, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1039, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1040, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1041, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1042, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1043, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1044, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1045, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1046, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1047, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1048, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1049, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1050, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1051, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1052, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1053, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1054, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1055, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1056, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1057, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1058, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1059, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1060, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1061, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1062, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1063, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1064, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1065, Action: 3, Reward: 3.0, Terminated: False, Truncated: False\n",
      "Step: 1066, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1067, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1068, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1069, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1070, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1071, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1072, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1073, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1074, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1075, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1076, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1077, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1078, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1079, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1080, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1081, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1082, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1083, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1084, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1085, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1086, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1087, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1088, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1089, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1090, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1091, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1092, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1093, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1094, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1095, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1096, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1097, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1098, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1099, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1100, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1101, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1102, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1103, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1104, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1105, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1106, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1107, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1108, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1109, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1110, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1111, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1112, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1113, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1114, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1115, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1116, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1117, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1118, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1119, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1120, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1121, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1122, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1123, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1124, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1125, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1126, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1127, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1128, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1129, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1130, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1131, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1132, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1133, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1134, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1135, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1136, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1137, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1138, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1139, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1140, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1141, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1142, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1143, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1144, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1145, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1146, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1147, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1148, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1149, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1150, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1151, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1152, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1153, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1154, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1155, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1156, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1157, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1158, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1159, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1160, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1161, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1162, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1163, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1164, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1165, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1166, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1167, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1168, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1169, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1170, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1171, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1172, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1173, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1174, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1175, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1176, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1177, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1178, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1179, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1180, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1181, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1182, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1183, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1184, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1185, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1186, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1187, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1188, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1189, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1190, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1191, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1192, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1193, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1194, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1195, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1196, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1197, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1198, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1199, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1200, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1201, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1202, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1203, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1204, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1205, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1206, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1207, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1208, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1209, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1210, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1211, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1212, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1213, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1214, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1215, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1216, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1217, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1218, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1219, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1220, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1221, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1222, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1223, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1224, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1225, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1226, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1227, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1228, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1229, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1230, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1231, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1232, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1233, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1234, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1235, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1236, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1237, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1238, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1239, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1240, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1241, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1242, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1243, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1244, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1245, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1246, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1247, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1248, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1249, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1250, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1251, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1252, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1253, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1254, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1255, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1256, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1257, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1258, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1259, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1260, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1261, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1262, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1263, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1264, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1265, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1266, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1267, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1268, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1269, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1270, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1271, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1272, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1273, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1274, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1275, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1276, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1277, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1278, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1279, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1280, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1281, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1282, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1283, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1284, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1285, Action: 0, Reward: 3.0, Terminated: False, Truncated: False\n",
      "Step: 1286, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1287, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1288, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1289, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1290, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1291, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1292, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1293, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1294, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1295, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1296, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1297, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1298, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1299, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1300, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1301, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1302, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1303, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1304, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1305, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1306, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1307, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1308, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1309, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1310, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1311, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1312, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1313, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1314, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1315, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1316, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1317, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1318, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1319, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1320, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1321, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1322, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1323, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1324, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1325, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1326, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1327, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1328, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1329, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1330, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1331, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1332, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1333, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1334, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1335, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1336, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1337, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1338, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1339, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1340, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1341, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1342, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1343, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1344, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1345, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1346, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1347, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1348, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1349, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1350, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1351, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1352, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1353, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1354, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1355, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1356, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1357, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1358, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1359, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1360, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1361, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1362, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1363, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1364, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1365, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1366, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1367, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1368, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1369, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1370, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1371, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1372, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1373, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1374, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1375, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1376, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1377, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1378, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1379, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1380, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1381, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1382, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1383, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1384, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1385, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1386, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1387, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1388, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1389, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1390, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1391, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1392, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1393, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1394, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1395, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1396, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1397, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1398, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1399, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1400, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1401, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1402, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1403, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1404, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1405, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1406, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1407, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1408, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1409, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1410, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1411, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1412, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1413, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1414, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1415, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1416, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1417, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1418, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1419, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1420, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1421, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1422, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1423, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1424, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1425, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1426, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1427, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1428, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1429, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1430, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1431, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1432, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1433, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1434, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1435, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1436, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1437, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1438, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1439, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1440, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1441, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1442, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1443, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1444, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1445, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1446, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1447, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1448, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1449, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1450, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1451, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1452, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1453, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1454, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1455, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1456, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1457, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1458, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1459, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1460, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1461, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1462, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1463, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1464, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1465, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1466, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1467, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1468, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1469, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1470, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1471, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1472, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1473, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1474, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1475, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1476, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1477, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1478, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1479, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1480, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1481, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1482, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1483, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1484, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1485, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1486, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1487, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1488, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1489, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1490, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1491, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1492, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1493, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1494, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1495, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1496, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1497, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1498, Action: 1, Reward: 3.0, Terminated: False, Truncated: False\n",
      "Step: 1499, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1500, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1501, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1502, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1503, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1504, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1505, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1506, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1507, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1508, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1509, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1510, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1511, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1512, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1513, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1514, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1515, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1516, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1517, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1518, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1519, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1520, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1521, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1522, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1523, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1524, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1525, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1526, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1527, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1528, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1529, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1530, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1531, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1532, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1533, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1534, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1535, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1536, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1537, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1538, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1539, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1540, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1541, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1542, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1543, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1544, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1545, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1546, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1547, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1548, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1549, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1550, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1551, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1552, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1553, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1554, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1555, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1556, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1557, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1558, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1559, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1560, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1561, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1562, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1563, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1564, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1565, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1566, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1567, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1568, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1569, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1570, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1571, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1572, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1573, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1574, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1575, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1576, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1577, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1578, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1579, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1580, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1581, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1582, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1583, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1584, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1585, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1586, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1587, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1588, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1589, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1590, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1591, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1592, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1593, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1594, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1595, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1596, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1597, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1598, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1599, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1600, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1601, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1602, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1603, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1604, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1605, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1606, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1607, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1608, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1609, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1610, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1611, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1612, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1613, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1614, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1615, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1616, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1617, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1618, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1619, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1620, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1621, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1622, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1623, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1624, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1625, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1626, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1627, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1628, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1629, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1630, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1631, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1632, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1633, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1634, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1635, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1636, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1637, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1638, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1639, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1640, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1641, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1642, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1643, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1644, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1645, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1646, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1647, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1648, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1649, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1650, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1651, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1652, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1653, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1654, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1655, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1656, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1657, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1658, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1659, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1660, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1661, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1662, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1663, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1664, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1665, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1666, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1667, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1668, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1669, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1670, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1671, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1672, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1673, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1674, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1675, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1676, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1677, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1678, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1679, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1680, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1681, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1682, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1683, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1684, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1685, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1686, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1687, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1688, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1689, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1690, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1691, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1692, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1693, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1694, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1695, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1696, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1697, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1698, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1699, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1700, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1701, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1702, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1703, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1704, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1705, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1706, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1707, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1708, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1709, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1710, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1711, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1712, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1713, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1714, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1715, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1716, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1717, Action: 4, Reward: 6.0, Terminated: False, Truncated: False\n",
      "Step: 1718, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1719, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1720, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1721, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1722, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1723, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1724, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1725, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1726, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1727, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1728, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1729, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1730, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1731, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1732, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1733, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1734, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1735, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1736, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1737, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1738, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1739, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1740, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1741, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1742, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1743, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1744, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1745, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1746, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1747, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1748, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1749, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1750, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1751, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1752, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1753, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1754, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1755, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1756, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1757, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1758, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1759, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1760, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1761, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1762, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1763, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1764, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1765, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1766, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1767, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1768, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1769, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1770, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1771, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1772, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1773, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1774, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1775, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1776, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1777, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1778, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1779, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1780, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1781, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1782, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1783, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1784, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1785, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1786, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1787, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1788, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1789, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1790, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1791, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1792, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1793, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1794, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1795, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1796, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1797, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1798, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1799, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1800, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1801, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1802, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1803, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1804, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1805, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1806, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1807, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1808, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1809, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1810, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1811, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1812, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1813, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1814, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1815, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1816, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1817, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1818, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1819, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1820, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1821, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1822, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1823, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1824, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1825, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1826, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1827, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1828, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1829, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1830, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1831, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1832, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1833, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1834, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1835, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1836, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1837, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1838, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1839, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1840, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1841, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1842, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1843, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1844, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1845, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1846, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1847, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1848, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1849, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1850, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1851, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1852, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1853, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1854, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1855, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1856, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1857, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1858, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1859, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1860, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1861, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1862, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1863, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1864, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1865, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1866, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1867, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1868, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1869, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1870, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1871, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1872, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1873, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1874, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1875, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1876, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1877, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1878, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1879, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1880, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1881, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1882, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1883, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1884, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1885, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1886, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1887, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1888, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1889, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1890, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1891, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1892, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1893, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1894, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1895, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1896, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1897, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1898, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1899, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1900, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1901, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1902, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1903, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1904, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1905, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1906, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1907, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1908, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1909, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1910, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1911, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1912, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1913, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1914, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1915, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1916, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1917, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1918, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1919, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1920, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1921, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1922, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1923, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1924, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1925, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1926, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1927, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1928, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1929, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1930, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1931, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1932, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1933, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1934, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1935, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1936, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1937, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1938, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1939, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1940, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1941, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1942, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1943, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1944, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1945, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1946, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1947, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1948, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1949, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1950, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1951, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1952, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1953, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1954, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1955, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1956, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1957, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1958, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1959, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1960, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1961, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1962, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1963, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1964, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1965, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1966, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1967, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1968, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1969, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1970, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1971, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1972, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1973, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1974, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1975, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1976, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1977, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1978, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1979, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1980, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1981, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1982, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1983, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1984, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1985, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1986, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1987, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1988, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1989, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1990, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1991, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1992, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1993, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1994, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1995, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1996, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1997, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1998, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 1999, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2000, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2001, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2002, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2003, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2004, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2005, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2006, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2007, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2008, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2009, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2010, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2011, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2012, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2013, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2014, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2015, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2016, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2017, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2018, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2019, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2020, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2021, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2022, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2023, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2024, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2025, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2026, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2027, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2028, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2029, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2030, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2031, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2032, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2033, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2034, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2035, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2036, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2037, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2038, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2039, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2040, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2041, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2042, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2043, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2044, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2045, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2046, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2047, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2048, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2049, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2050, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2051, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2052, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2053, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2054, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2055, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2056, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2057, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2058, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2059, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2060, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2061, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2062, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2063, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2064, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2065, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2066, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2067, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2068, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2069, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2070, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2071, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2072, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2073, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2074, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2075, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2076, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2077, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2078, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2079, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2080, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2081, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2082, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2083, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2084, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2085, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2086, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2087, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2088, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2089, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2090, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2091, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2092, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2093, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2094, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2095, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2096, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2097, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2098, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2099, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2100, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2101, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2102, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2103, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2104, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2105, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2106, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2107, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2108, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2109, Action: 3, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2110, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2111, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2112, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2113, Action: 0, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2114, Action: 2, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2115, Action: 1, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2116, Action: 4, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2117, Action: 5, Reward: 0.0, Terminated: False, Truncated: False\n",
      "Step: 2118, Action: 5, Reward: 0.0, Terminated: True, Truncated: False\n",
      "Round 1 finished after 2118 steps with total reward: 22.0\n",
      "\n",
      "--- End of 10 Rounds ---\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import time\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "env = gym.make(\"ALE/Bowling-v5\", render_mode=\"human\")\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "print(\"Observation shape:\", observation.shape)\n",
    "print(\"Observation data type:\", observation.dtype)\n",
    "print(\"Action space:\", env.action_space)\n",
    "\n",
    "num_rounds = 1\n",
    "for round_num in range(num_rounds):\n",
    "    print(f\"\\n--- Round {round_num + 1} ---\")\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    total_reward = 0\n",
    "    step = 0\n",
    "    while not terminated and not truncated:\n",
    "        action = env.action_space.sample()\n",
    "        next_observation, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        step += 1\n",
    "        print(f\"Step: {step}, Action: {action}, Reward: {reward}, Terminated: {terminated}, Truncated: {truncated}\")\n",
    "        env.render()\n",
    "        time.sleep(0.1)  # Add a small delay to see what's happening\n",
    "\n",
    "        # In Bowling, an episode typically ends after all frames are played.\n",
    "        # We'll rely on the environment's 'terminated' flag to signal the end of the game.\n",
    "        if terminated or truncated:\n",
    "            print(f\"Round {round_num + 1} finished after {step} steps with total reward: {total_reward}\")\n",
    "            observation, info = env.reset()\n",
    "            break\n",
    "\n",
    "    if round_num == num_rounds - 1:\n",
    "        print(\"\\n--- End of 10 Rounds ---\")\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301198fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual frame stacking and preprocessing\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "\n",
    "class ManualPreprocessWrapper(gym.Wrapper):\n",
    "    def _init_(self, env, frame_stack=4):\n",
    "        super()._init_(env)\n",
    "        self.frame_stack = frame_stack\n",
    "        self.frames = deque(maxlen=frame_stack)\n",
    "\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(frame_stack, 84, 84),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        processed = self._preprocess(obs)\n",
    "        for _ in range(self.frame_stack):\n",
    "            self.frames.append(processed)\n",
    "        return np.stack(self.frames, axis=0), info\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        processed = self._preprocess(obs)\n",
    "        self.frames.append(processed)\n",
    "        return np.stack(self.frames, axis=0), reward, terminated, truncated, info\n",
    "\n",
    "    def _preprocess(self, obs):\n",
    "        gray = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
    "        resized = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "        return resized.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2fa2e7",
   "metadata": {},
   "source": [
    "## Import the Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c60351e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical # For sampling actions\n",
    "import numpy as np # For array manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655d88bc",
   "metadata": {},
   "source": [
    "## Define Actor and Critic Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60fe7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PPO Specific Components ---\n",
    "\n",
    "# Helper function for common CNN layers (optional, but good practice)\n",
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        # Assuming observation shape is (210, 160, 3) - (H, W, C)\n",
    "        # PyTorch CNNs expect (C, H, W)\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Conv2d(3, 32, kernel_size=8, stride=4)), # Input channels = 3 (RGB)\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(32, 64, kernel_size=4, stride=2)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(64, 64, kernel_size=3, stride=1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            # Calculate the flattened size carefully based on conv output\n",
    "            # For (210,160,3) input:\n",
    "            # After conv1: (210-8)/4 + 1 = 51.5 -> 51. (160-8)/4+1 = 39\n",
    "            # After conv2: (51-4)/2 + 1 = 24.5 -> 24. (39-4)/2+1 = 18.5 -> 18\n",
    "            # After conv3: (24-3)/1 + 1 = 22. (18-3)/1+1 = 16\n",
    "            # Flattened size = 64 * 22 * 16 = 22528\n",
    "            # This might need adjustment based on actual output dimensions or padding.\n",
    "            # A common practice is to use env.observation_space.shape and a dummy forward pass to get the size.\n",
    "            layer_init(nn.Linear(64 * 22 * 16, 512)), # Example flattened size, ADJUST THIS\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(512, num_actions), std=0.01) # Output layer for action logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Preprocess x: normalize and permute dimensions if necessary\n",
    "        # x is expected to be (Batch, Height, Width, Channels) from Gym\n",
    "        # Permute to (Batch, Channels, Height, Width) for PyTorch Conv2D\n",
    "        x = x.permute(0, 3, 1, 2) / 255.0 # Normalize pixel values\n",
    "        return self.network(x)\n",
    "\n",
    "    def get_action_and_value(self, x, action=None): # Renaming to include value if actor and critic share layers\n",
    "        logits = self.forward(x)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy() # Return action, log_prob, entropy\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        # Similar CNN structure as the Actor, or can share layers\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Conv2d(3, 32, kernel_size=8, stride=4)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(32, 64, kernel_size=4, stride=2)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(64, 64, kernel_size=3, stride=1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            layer_init(nn.Linear(64 * 22 * 16, 512)), # Example flattened size, ADJUST THIS\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(512, 1), std=1.0) # Output layer for state value\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2) / 255.0 # Normalize pixel values\n",
    "        return self.network(x)\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "# IMPORTANT: Calculate the input size to the first nn.Linear layer in Actor and Critic\n",
    "# after the convolutional and flatten layers dynamically.\n",
    "# You can do this by creating a dummy input and passing it through the conv layers:\n",
    "# temp_env = gym.make(\"ALE/Bowling-v5\")\n",
    "# obs_shape = temp_env.observation_space.shape # (210, 160, 3)\n",
    "# cnn_base = nn.Sequential(\n",
    "#     layer_init(nn.Conv2d(obs_shape[2], 32, kernel_size=8, stride=4)), nn.ReLU(),\n",
    "#     layer_init(nn.Conv2d(32, 64, kernel_size=4, stride=2)), nn.ReLU(),\n",
    "#     layer_init(nn.Conv2d(64, 64, kernel_size=3, stride=1)), nn.ReLU(),\n",
    "#     nn.Flatten()\n",
    "# )\n",
    "# with torch.no_grad():\n",
    "#     # Create a dummy batch of observations (1, C, H, W)\n",
    "#     dummy_obs = torch.zeros(1, obs_shape[2], obs_shape[0], obs_shape[1])\n",
    "#     flattened_size = cnn_base(dummy_obs).shape[1]\n",
    "# print(f\"Calculated flattened size: {flattened_size}\")\n",
    "# # Replace 64 * 22 * 16 with this 'flattened_size'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79abeaf3",
   "metadata": {},
   "source": [
    "## Define PPO Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff840109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO Hyperparameters\n",
    "LEARNING_RATE = 2.5e-4\n",
    "NUM_ENVS = 1 # For now, we're not vectorizing, but good to have as a variable\n",
    "NUM_STEPS_PER_ROLLOUT = 128 # Number of steps to run in the environment per policy update\n",
    "GAMMA = 0.99 # Discount factor\n",
    "GAE_LAMBDA = 0.95 # Lambda for GAE\n",
    "NUM_MINIBATCHES = 4 # Number of minibatches to split a batch into\n",
    "CLIP_EPS = 0.1 # PPO clip parameter\n",
    "NUM_EPOCHS_PER_UPDATE = 4 # Number of epochs to update policy per batch\n",
    "ENTROPY_COEF = 0.01 # Entropy coefficient\n",
    "VALUE_LOSS_COEF = 0.5 # Value function loss coefficient\n",
    "MAX_GRAD_NORM = 0.5 # Max gradient norm for clipping\n",
    "TARGET_KL = None # Optional: Target KL divergence for early stopping\n",
    "\n",
    "# Training settings\n",
    "TOTAL_TIMESTEPS = 500_000 # Total number of timesteps to train for\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa300ec5",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c40c108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamically calculated flattened size for Linear layer: 22528\n"
     ]
    }
   ],
   "source": [
    "# 1. Environment Setup (Your existing code)\n",
    "gym.register_envs(ale_py)\n",
    "# If you want to try without human rendering for speed:\n",
    "# env = gym.make(\"ALE/Bowling-v5\")\n",
    "env = gym.make(\"ALE/Bowling-v5\", render_mode=\"human\") # Keep for now if you want to see it\n",
    "observation_shape = env.observation_space.shape\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "# --- PPO Specific Components ---\n",
    "# Dynamically calculate flattened size\n",
    "cnn_base_test = nn.Sequential(\n",
    "    layer_init(nn.Conv2d(observation_shape[2], 32, kernel_size=8, stride=4)), nn.ReLU(),\n",
    "    layer_init(nn.Conv2d(32, 64, kernel_size=4, stride=2)), nn.ReLU(),\n",
    "    layer_init(nn.Conv2d(64, 64, kernel_size=3, stride=1)), nn.ReLU(),\n",
    "    nn.Flatten()\n",
    ")\n",
    "with torch.no_grad():\n",
    "    dummy_obs_for_size = torch.zeros(1, observation_shape[2], observation_shape[0], observation_shape[1])\n",
    "    flattened_size = cnn_base_test(dummy_obs_for_size).shape[1]\n",
    "print(f\"Dynamically calculated flattened size for Linear layer: {flattened_size}\")\n",
    "\n",
    "# Re-define Actor and Critic with the correct flattened_size\n",
    "class ActorNetwork(nn.Module): # Redefine with correct flattened_size\n",
    "    def __init__(self, num_actions, input_channels=3): # input_channels for clarity\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Conv2d(input_channels, 32, kernel_size=8, stride=4)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(32, 64, kernel_size=4, stride=2)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(64, 64, kernel_size=3, stride=1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            layer_init(nn.Linear(flattened_size, 512)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(512, num_actions), std=0.01)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # x is (Batch, Height, Width, Channels)\n",
    "        x = x.permute(0, 3, 1, 2) / 255.0 # (Batch, Channels, Height, Width)\n",
    "        return self.network(x)\n",
    "    # ... (get_action_and_value remains the same)\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        logits = self.forward(x)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy()\n",
    "\n",
    "class CriticNetwork(nn.Module): # Redefine with correct flattened_size\n",
    "    def __init__(self, input_channels=3):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Conv2d(input_channels, 32, kernel_size=8, stride=4)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(32, 64, kernel_size=4, stride=2)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(64, 64, kernel_size=3, stride=1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            layer_init(nn.Linear(flattened_size, 512)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(512, 1), std=1.0)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2) / 255.0\n",
    "        return self.network(x)\n",
    "    # ... (get_value remains the same)\n",
    "    def get_value(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "\n",
    "actor = ActorNetwork(num_actions, input_channels=observation_shape[2]).to(DEVICE)\n",
    "critic = CriticNetwork(input_channels=observation_shape[2]).to(DEVICE)\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=LEARNING_RATE, eps=1e-5)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=LEARNING_RATE, eps=1e-5)\n",
    "\n",
    "# Storage for rollouts\n",
    "obs_storage = torch.zeros((NUM_STEPS_PER_ROLLOUT, NUM_ENVS) + observation_shape).to(DEVICE)\n",
    "actions_storage = torch.zeros((NUM_STEPS_PER_ROLLOUT, NUM_ENVS)).to(DEVICE) # For Discrete actions\n",
    "logprobs_storage = torch.zeros((NUM_STEPS_PER_ROLLOUT, NUM_ENVS)).to(DEVICE)\n",
    "rewards_storage = torch.zeros((NUM_STEPS_PER_ROLLOUT, NUM_ENVS)).to(DEVICE)\n",
    "dones_storage = torch.zeros((NUM_STEPS_PER_ROLLOUT, NUM_ENVS)).to(DEVICE)\n",
    "values_storage = torch.zeros((NUM_STEPS_PER_ROLLOUT, NUM_ENVS)).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c82c46",
   "metadata": {},
   "source": [
    "## Evaluation Setupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c53d2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = gym.make(\"ALE/Bowling-v5\")  \n",
    "eval_freq = 10  # Evaluate every 10 updates\n",
    "eval_results = []  # Stores (global_step, mean_reward, std_reward)\n",
    "\n",
    "def evaluate(policy, num_episodes=10):\n",
    "    policy.eval()\n",
    "    rewards = []\n",
    "    for _ in range(num_episodes):\n",
    "        obs, _ = eval_env.reset()\n",
    "        episode_reward = 0\n",
    "        while True:\n",
    "            with torch.no_grad():\n",
    "                action, _, _ = policy.get_action_and_value(\n",
    "                    torch.Tensor(obs).unsqueeze(0).to(DEVICE)\n",
    "                )\n",
    "            obs, reward, terminated, truncated, _ = eval_env.step(action.item())\n",
    "            episode_reward += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        rewards.append(episode_reward)\n",
    "    policy.train()\n",
    "    return np.mean(rewards), np.std(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da1d91",
   "metadata": {},
   "source": [
    "## Main loop to run in timesteps and not in num_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a72d2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "--- Evaluation after Update 1 ---\n",
      "Total Timesteps: 128\n",
      "Mean Reward: 23.5 ± 4.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1/3906\n",
      "Global Step: 128\n",
      "Approx KL Divergence: 0.002\n",
      "Clip Fraction: 0.188\n",
      "Value Loss: 0.004\n",
      "Update 1/3906, Global Timesteps: 128\n",
      "\n",
      "--- Evaluation after Update 10 ---\n",
      "Total Timesteps: 1280\n",
      "Mean Reward: 22.6 ± 3.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 10/3906\n",
      "Global Step: 1280\n",
      "Approx KL Divergence: 0.005\n",
      "Clip Fraction: 0.166\n",
      "Value Loss: 1.159\n",
      "Update 10/3906, Global Timesteps: 1280\n",
      "\n",
      "--- Evaluation after Update 20 ---\n",
      "Total Timesteps: 2560\n",
      "Mean Reward: 21.7 ± 3.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 20/3906\n",
      "Global Step: 2560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 20/3906, Global Timesteps: 2560\n",
      "\n",
      "--- Evaluation after Update 30 ---\n",
      "Total Timesteps: 3840\n",
      "Mean Reward: 24.1 ± 4.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 30/3906\n",
      "Global Step: 3840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 30/3906, Global Timesteps: 3840\n",
      "\n",
      "--- Evaluation after Update 40 ---\n",
      "Total Timesteps: 5120\n",
      "Mean Reward: 22.3 ± 8.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 40/3906\n",
      "Global Step: 5120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 40/3906, Global Timesteps: 5120\n",
      "\n",
      "--- Evaluation after Update 50 ---\n",
      "Total Timesteps: 6400\n",
      "Mean Reward: 25.4 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 50/3906\n",
      "Global Step: 6400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 50/3906, Global Timesteps: 6400\n",
      "\n",
      "--- Evaluation after Update 60 ---\n",
      "Total Timesteps: 7680\n",
      "Mean Reward: 24.3 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 60/3906\n",
      "Global Step: 7680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 60/3906, Global Timesteps: 7680\n",
      "\n",
      "--- Evaluation after Update 70 ---\n",
      "Total Timesteps: 8960\n",
      "Mean Reward: 23.4 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 70/3906\n",
      "Global Step: 8960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 70/3906, Global Timesteps: 8960\n",
      "\n",
      "--- Evaluation after Update 80 ---\n",
      "Total Timesteps: 10240\n",
      "Mean Reward: 22.0 ± 4.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 80/3906\n",
      "Global Step: 10240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 80/3906, Global Timesteps: 10240\n",
      "\n",
      "--- Evaluation after Update 90 ---\n",
      "Total Timesteps: 11520\n",
      "Mean Reward: 24.3 ± 6.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 90/3906\n",
      "Global Step: 11520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 90/3906, Global Timesteps: 11520\n",
      "\n",
      "--- Evaluation after Update 100 ---\n",
      "Total Timesteps: 12800\n",
      "Mean Reward: 22.3 ± 7.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 100/3906\n",
      "Global Step: 12800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 100/3906, Global Timesteps: 12800\n",
      "\n",
      "--- Evaluation after Update 110 ---\n",
      "Total Timesteps: 14080\n",
      "Mean Reward: 20.9 ± 3.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 110/3906\n",
      "Global Step: 14080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 110/3906, Global Timesteps: 14080\n",
      "\n",
      "--- Evaluation after Update 120 ---\n",
      "Total Timesteps: 15360\n",
      "Mean Reward: 25.1 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 120/3906\n",
      "Global Step: 15360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 120/3906, Global Timesteps: 15360\n",
      "\n",
      "--- Evaluation after Update 130 ---\n",
      "Total Timesteps: 16640\n",
      "Mean Reward: 22.4 ± 5.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 130/3906\n",
      "Global Step: 16640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 130/3906, Global Timesteps: 16640\n",
      "\n",
      "--- Evaluation after Update 140 ---\n",
      "Total Timesteps: 17920\n",
      "Mean Reward: 23.5 ± 3.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 140/3906\n",
      "Global Step: 17920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 140/3906, Global Timesteps: 17920\n",
      "\n",
      "--- Evaluation after Update 150 ---\n",
      "Total Timesteps: 19200\n",
      "Mean Reward: 24.8 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 150/3906\n",
      "Global Step: 19200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 150/3906, Global Timesteps: 19200\n",
      "\n",
      "--- Evaluation after Update 160 ---\n",
      "Total Timesteps: 20480\n",
      "Mean Reward: 25.7 ± 2.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 160/3906\n",
      "Global Step: 20480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 160/3906, Global Timesteps: 20480\n",
      "\n",
      "--- Evaluation after Update 170 ---\n",
      "Total Timesteps: 21760\n",
      "Mean Reward: 23.5 ± 3.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 170/3906\n",
      "Global Step: 21760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 170/3906, Global Timesteps: 21760\n",
      "\n",
      "--- Evaluation after Update 180 ---\n",
      "Total Timesteps: 23040\n",
      "Mean Reward: 19.5 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 180/3906\n",
      "Global Step: 23040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 180/3906, Global Timesteps: 23040\n",
      "\n",
      "--- Evaluation after Update 190 ---\n",
      "Total Timesteps: 24320\n",
      "Mean Reward: 22.8 ± 4.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 190/3906\n",
      "Global Step: 24320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 190/3906, Global Timesteps: 24320\n",
      "\n",
      "--- Evaluation after Update 200 ---\n",
      "Total Timesteps: 25600\n",
      "Mean Reward: 19.3 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 200/3906\n",
      "Global Step: 25600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 200/3906, Global Timesteps: 25600\n",
      "\n",
      "--- Evaluation after Update 210 ---\n",
      "Total Timesteps: 26880\n",
      "Mean Reward: 24.5 ± 4.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 210/3906\n",
      "Global Step: 26880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 210/3906, Global Timesteps: 26880\n",
      "\n",
      "--- Evaluation after Update 220 ---\n",
      "Total Timesteps: 28160\n",
      "Mean Reward: 23.4 ± 5.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 220/3906\n",
      "Global Step: 28160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 220/3906, Global Timesteps: 28160\n",
      "\n",
      "--- Evaluation after Update 230 ---\n",
      "Total Timesteps: 29440\n",
      "Mean Reward: 25.2 ± 7.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 230/3906\n",
      "Global Step: 29440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 230/3906, Global Timesteps: 29440\n",
      "\n",
      "--- Evaluation after Update 240 ---\n",
      "Total Timesteps: 30720\n",
      "Mean Reward: 23.7 ± 3.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 240/3906\n",
      "Global Step: 30720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 240/3906, Global Timesteps: 30720\n",
      "\n",
      "--- Evaluation after Update 250 ---\n",
      "Total Timesteps: 32000\n",
      "Mean Reward: 23.9 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 250/3906\n",
      "Global Step: 32000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 250/3906, Global Timesteps: 32000\n",
      "\n",
      "--- Evaluation after Update 260 ---\n",
      "Total Timesteps: 33280\n",
      "Mean Reward: 22.6 ± 6.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 260/3906\n",
      "Global Step: 33280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 260/3906, Global Timesteps: 33280\n",
      "\n",
      "--- Evaluation after Update 270 ---\n",
      "Total Timesteps: 34560\n",
      "Mean Reward: 24.6 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 270/3906\n",
      "Global Step: 34560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 270/3906, Global Timesteps: 34560\n",
      "\n",
      "--- Evaluation after Update 280 ---\n",
      "Total Timesteps: 35840\n",
      "Mean Reward: 25.1 ± 6.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 280/3906\n",
      "Global Step: 35840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 280/3906, Global Timesteps: 35840\n",
      "\n",
      "--- Evaluation after Update 290 ---\n",
      "Total Timesteps: 37120\n",
      "Mean Reward: 24.3 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 290/3906\n",
      "Global Step: 37120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 290/3906, Global Timesteps: 37120\n",
      "\n",
      "--- Evaluation after Update 300 ---\n",
      "Total Timesteps: 38400\n",
      "Mean Reward: 24.2 ± 6.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 300/3906\n",
      "Global Step: 38400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 300/3906, Global Timesteps: 38400\n",
      "\n",
      "--- Evaluation after Update 310 ---\n",
      "Total Timesteps: 39680\n",
      "Mean Reward: 21.9 ± 6.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 310/3906\n",
      "Global Step: 39680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 310/3906, Global Timesteps: 39680\n",
      "\n",
      "--- Evaluation after Update 320 ---\n",
      "Total Timesteps: 40960\n",
      "Mean Reward: 24.8 ± 6.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 320/3906\n",
      "Global Step: 40960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 320/3906, Global Timesteps: 40960\n",
      "\n",
      "--- Evaluation after Update 330 ---\n",
      "Total Timesteps: 42240\n",
      "Mean Reward: 23.8 ± 5.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 330/3906\n",
      "Global Step: 42240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 330/3906, Global Timesteps: 42240\n",
      "\n",
      "--- Evaluation after Update 340 ---\n",
      "Total Timesteps: 43520\n",
      "Mean Reward: 23.3 ± 3.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 340/3906\n",
      "Global Step: 43520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 340/3906, Global Timesteps: 43520\n",
      "\n",
      "--- Evaluation after Update 350 ---\n",
      "Total Timesteps: 44800\n",
      "Mean Reward: 24.4 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 350/3906\n",
      "Global Step: 44800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 350/3906, Global Timesteps: 44800\n",
      "\n",
      "--- Evaluation after Update 360 ---\n",
      "Total Timesteps: 46080\n",
      "Mean Reward: 22.3 ± 5.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 360/3906\n",
      "Global Step: 46080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 360/3906, Global Timesteps: 46080\n",
      "\n",
      "--- Evaluation after Update 370 ---\n",
      "Total Timesteps: 47360\n",
      "Mean Reward: 22.5 ± 4.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 370/3906\n",
      "Global Step: 47360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 370/3906, Global Timesteps: 47360\n",
      "\n",
      "--- Evaluation after Update 380 ---\n",
      "Total Timesteps: 48640\n",
      "Mean Reward: 24.2 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 380/3906\n",
      "Global Step: 48640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 380/3906, Global Timesteps: 48640\n",
      "\n",
      "--- Evaluation after Update 390 ---\n",
      "Total Timesteps: 49920\n",
      "Mean Reward: 23.9 ± 3.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 390/3906\n",
      "Global Step: 49920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 390/3906, Global Timesteps: 49920\n",
      "\n",
      "--- Evaluation after Update 400 ---\n",
      "Total Timesteps: 51200\n",
      "Mean Reward: 22.1 ± 2.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 400/3906\n",
      "Global Step: 51200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 400/3906, Global Timesteps: 51200\n",
      "\n",
      "--- Evaluation after Update 410 ---\n",
      "Total Timesteps: 52480\n",
      "Mean Reward: 21.4 ± 7.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 410/3906\n",
      "Global Step: 52480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 410/3906, Global Timesteps: 52480\n",
      "\n",
      "--- Evaluation after Update 420 ---\n",
      "Total Timesteps: 53760\n",
      "Mean Reward: 26.1 ± 8.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 420/3906\n",
      "Global Step: 53760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 420/3906, Global Timesteps: 53760\n",
      "\n",
      "--- Evaluation after Update 430 ---\n",
      "Total Timesteps: 55040\n",
      "Mean Reward: 24.5 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 430/3906\n",
      "Global Step: 55040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 430/3906, Global Timesteps: 55040\n",
      "\n",
      "--- Evaluation after Update 440 ---\n",
      "Total Timesteps: 56320\n",
      "Mean Reward: 26.2 ± 8.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 440/3906\n",
      "Global Step: 56320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 440/3906, Global Timesteps: 56320\n",
      "\n",
      "--- Evaluation after Update 450 ---\n",
      "Total Timesteps: 57600\n",
      "Mean Reward: 24.3 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 450/3906\n",
      "Global Step: 57600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 450/3906, Global Timesteps: 57600\n",
      "\n",
      "--- Evaluation after Update 460 ---\n",
      "Total Timesteps: 58880\n",
      "Mean Reward: 24.5 ± 6.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 460/3906\n",
      "Global Step: 58880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 460/3906, Global Timesteps: 58880\n",
      "\n",
      "--- Evaluation after Update 470 ---\n",
      "Total Timesteps: 60160\n",
      "Mean Reward: 25.8 ± 5.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 470/3906\n",
      "Global Step: 60160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 470/3906, Global Timesteps: 60160\n",
      "\n",
      "--- Evaluation after Update 480 ---\n",
      "Total Timesteps: 61440\n",
      "Mean Reward: 19.8 ± 4.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 480/3906\n",
      "Global Step: 61440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 480/3906, Global Timesteps: 61440\n",
      "\n",
      "--- Evaluation after Update 490 ---\n",
      "Total Timesteps: 62720\n",
      "Mean Reward: 24.7 ± 3.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 490/3906\n",
      "Global Step: 62720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 490/3906, Global Timesteps: 62720\n",
      "\n",
      "--- Evaluation after Update 500 ---\n",
      "Total Timesteps: 64000\n",
      "Mean Reward: 23.2 ± 4.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 500/3906\n",
      "Global Step: 64000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 500/3906, Global Timesteps: 64000\n",
      "\n",
      "--- Evaluation after Update 510 ---\n",
      "Total Timesteps: 65280\n",
      "Mean Reward: 25.6 ± 6.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 510/3906\n",
      "Global Step: 65280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 510/3906, Global Timesteps: 65280\n",
      "\n",
      "--- Evaluation after Update 520 ---\n",
      "Total Timesteps: 66560\n",
      "Mean Reward: 27.0 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 520/3906\n",
      "Global Step: 66560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 520/3906, Global Timesteps: 66560\n",
      "\n",
      "--- Evaluation after Update 530 ---\n",
      "Total Timesteps: 67840\n",
      "Mean Reward: 21.8 ± 4.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 530/3906\n",
      "Global Step: 67840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 530/3906, Global Timesteps: 67840\n",
      "\n",
      "--- Evaluation after Update 540 ---\n",
      "Total Timesteps: 69120\n",
      "Mean Reward: 25.5 ± 7.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 540/3906\n",
      "Global Step: 69120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 540/3906, Global Timesteps: 69120\n",
      "\n",
      "--- Evaluation after Update 550 ---\n",
      "Total Timesteps: 70400\n",
      "Mean Reward: 26.4 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 550/3906\n",
      "Global Step: 70400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 550/3906, Global Timesteps: 70400\n",
      "\n",
      "--- Evaluation after Update 560 ---\n",
      "Total Timesteps: 71680\n",
      "Mean Reward: 23.0 ± 5.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 560/3906\n",
      "Global Step: 71680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 560/3906, Global Timesteps: 71680\n",
      "\n",
      "--- Evaluation after Update 570 ---\n",
      "Total Timesteps: 72960\n",
      "Mean Reward: 23.2 ± 6.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 570/3906\n",
      "Global Step: 72960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 570/3906, Global Timesteps: 72960\n",
      "\n",
      "--- Evaluation after Update 580 ---\n",
      "Total Timesteps: 74240\n",
      "Mean Reward: 23.9 ± 5.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 580/3906\n",
      "Global Step: 74240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 580/3906, Global Timesteps: 74240\n",
      "\n",
      "--- Evaluation after Update 590 ---\n",
      "Total Timesteps: 75520\n",
      "Mean Reward: 24.2 ± 6.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 590/3906\n",
      "Global Step: 75520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 590/3906, Global Timesteps: 75520\n",
      "\n",
      "--- Evaluation after Update 600 ---\n",
      "Total Timesteps: 76800\n",
      "Mean Reward: 24.2 ± 3.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 600/3906\n",
      "Global Step: 76800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 600/3906, Global Timesteps: 76800\n",
      "\n",
      "--- Evaluation after Update 610 ---\n",
      "Total Timesteps: 78080\n",
      "Mean Reward: 23.4 ± 5.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 610/3906\n",
      "Global Step: 78080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 610/3906, Global Timesteps: 78080\n",
      "\n",
      "--- Evaluation after Update 620 ---\n",
      "Total Timesteps: 79360\n",
      "Mean Reward: 26.0 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 620/3906\n",
      "Global Step: 79360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 620/3906, Global Timesteps: 79360\n",
      "\n",
      "--- Evaluation after Update 630 ---\n",
      "Total Timesteps: 80640\n",
      "Mean Reward: 25.0 ± 4.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 630/3906\n",
      "Global Step: 80640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 630/3906, Global Timesteps: 80640\n",
      "\n",
      "--- Evaluation after Update 640 ---\n",
      "Total Timesteps: 81920\n",
      "Mean Reward: 21.7 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 640/3906\n",
      "Global Step: 81920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 640/3906, Global Timesteps: 81920\n",
      "\n",
      "--- Evaluation after Update 650 ---\n",
      "Total Timesteps: 83200\n",
      "Mean Reward: 24.7 ± 8.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 650/3906\n",
      "Global Step: 83200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 650/3906, Global Timesteps: 83200\n",
      "\n",
      "--- Evaluation after Update 660 ---\n",
      "Total Timesteps: 84480\n",
      "Mean Reward: 24.9 ± 3.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 660/3906\n",
      "Global Step: 84480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 660/3906, Global Timesteps: 84480\n",
      "\n",
      "--- Evaluation after Update 670 ---\n",
      "Total Timesteps: 85760\n",
      "Mean Reward: 24.2 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 670/3906\n",
      "Global Step: 85760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 670/3906, Global Timesteps: 85760\n",
      "\n",
      "--- Evaluation after Update 680 ---\n",
      "Total Timesteps: 87040\n",
      "Mean Reward: 23.9 ± 3.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 680/3906\n",
      "Global Step: 87040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 680/3906, Global Timesteps: 87040\n",
      "\n",
      "--- Evaluation after Update 690 ---\n",
      "Total Timesteps: 88320\n",
      "Mean Reward: 21.1 ± 4.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 690/3906\n",
      "Global Step: 88320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 690/3906, Global Timesteps: 88320\n",
      "\n",
      "--- Evaluation after Update 700 ---\n",
      "Total Timesteps: 89600\n",
      "Mean Reward: 25.1 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 700/3906\n",
      "Global Step: 89600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 700/3906, Global Timesteps: 89600\n",
      "\n",
      "--- Evaluation after Update 710 ---\n",
      "Total Timesteps: 90880\n",
      "Mean Reward: 24.2 ± 3.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 710/3906\n",
      "Global Step: 90880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 710/3906, Global Timesteps: 90880\n",
      "\n",
      "--- Evaluation after Update 720 ---\n",
      "Total Timesteps: 92160\n",
      "Mean Reward: 24.8 ± 6.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 720/3906\n",
      "Global Step: 92160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 720/3906, Global Timesteps: 92160\n",
      "\n",
      "--- Evaluation after Update 730 ---\n",
      "Total Timesteps: 93440\n",
      "Mean Reward: 26.6 ± 5.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 730/3906\n",
      "Global Step: 93440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 730/3906, Global Timesteps: 93440\n",
      "\n",
      "--- Evaluation after Update 740 ---\n",
      "Total Timesteps: 94720\n",
      "Mean Reward: 25.2 ± 3.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 740/3906\n",
      "Global Step: 94720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 740/3906, Global Timesteps: 94720\n",
      "\n",
      "--- Evaluation after Update 750 ---\n",
      "Total Timesteps: 96000\n",
      "Mean Reward: 25.3 ± 3.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 750/3906\n",
      "Global Step: 96000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 750/3906, Global Timesteps: 96000\n",
      "\n",
      "--- Evaluation after Update 760 ---\n",
      "Total Timesteps: 97280\n",
      "Mean Reward: 27.3 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 760/3906\n",
      "Global Step: 97280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 760/3906, Global Timesteps: 97280\n",
      "\n",
      "--- Evaluation after Update 770 ---\n",
      "Total Timesteps: 98560\n",
      "Mean Reward: 23.4 ± 6.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 770/3906\n",
      "Global Step: 98560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 770/3906, Global Timesteps: 98560\n",
      "\n",
      "--- Evaluation after Update 780 ---\n",
      "Total Timesteps: 99840\n",
      "Mean Reward: 28.1 ± 5.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 780/3906\n",
      "Global Step: 99840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 780/3906, Global Timesteps: 99840\n",
      "\n",
      "--- Evaluation after Update 790 ---\n",
      "Total Timesteps: 101120\n",
      "Mean Reward: 22.7 ± 6.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 790/3906\n",
      "Global Step: 101120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 790/3906, Global Timesteps: 101120\n",
      "\n",
      "--- Evaluation after Update 800 ---\n",
      "Total Timesteps: 102400\n",
      "Mean Reward: 23.1 ± 6.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 800/3906\n",
      "Global Step: 102400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 800/3906, Global Timesteps: 102400\n",
      "\n",
      "--- Evaluation after Update 810 ---\n",
      "Total Timesteps: 103680\n",
      "Mean Reward: 23.1 ± 3.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 810/3906\n",
      "Global Step: 103680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 810/3906, Global Timesteps: 103680\n",
      "\n",
      "--- Evaluation after Update 820 ---\n",
      "Total Timesteps: 104960\n",
      "Mean Reward: 18.7 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 820/3906\n",
      "Global Step: 104960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 820/3906, Global Timesteps: 104960\n",
      "\n",
      "--- Evaluation after Update 830 ---\n",
      "Total Timesteps: 106240\n",
      "Mean Reward: 20.8 ± 3.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 830/3906\n",
      "Global Step: 106240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 830/3906, Global Timesteps: 106240\n",
      "\n",
      "--- Evaluation after Update 840 ---\n",
      "Total Timesteps: 107520\n",
      "Mean Reward: 25.4 ± 5.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 840/3906\n",
      "Global Step: 107520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 840/3906, Global Timesteps: 107520\n",
      "\n",
      "--- Evaluation after Update 850 ---\n",
      "Total Timesteps: 108800\n",
      "Mean Reward: 24.1 ± 6.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 850/3906\n",
      "Global Step: 108800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 850/3906, Global Timesteps: 108800\n",
      "\n",
      "--- Evaluation after Update 860 ---\n",
      "Total Timesteps: 110080\n",
      "Mean Reward: 23.0 ± 5.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 860/3906\n",
      "Global Step: 110080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 860/3906, Global Timesteps: 110080\n",
      "\n",
      "--- Evaluation after Update 870 ---\n",
      "Total Timesteps: 111360\n",
      "Mean Reward: 23.9 ± 7.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 870/3906\n",
      "Global Step: 111360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 870/3906, Global Timesteps: 111360\n",
      "\n",
      "--- Evaluation after Update 880 ---\n",
      "Total Timesteps: 112640\n",
      "Mean Reward: 22.4 ± 5.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 880/3906\n",
      "Global Step: 112640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 880/3906, Global Timesteps: 112640\n",
      "\n",
      "--- Evaluation after Update 890 ---\n",
      "Total Timesteps: 113920\n",
      "Mean Reward: 25.9 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 890/3906\n",
      "Global Step: 113920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 890/3906, Global Timesteps: 113920\n",
      "\n",
      "--- Evaluation after Update 900 ---\n",
      "Total Timesteps: 115200\n",
      "Mean Reward: 23.2 ± 3.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 900/3906\n",
      "Global Step: 115200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 900/3906, Global Timesteps: 115200\n",
      "\n",
      "--- Evaluation after Update 910 ---\n",
      "Total Timesteps: 116480\n",
      "Mean Reward: 22.9 ± 6.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 910/3906\n",
      "Global Step: 116480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 910/3906, Global Timesteps: 116480\n",
      "\n",
      "--- Evaluation after Update 920 ---\n",
      "Total Timesteps: 117760\n",
      "Mean Reward: 24.5 ± 6.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 920/3906\n",
      "Global Step: 117760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 920/3906, Global Timesteps: 117760\n",
      "\n",
      "--- Evaluation after Update 930 ---\n",
      "Total Timesteps: 119040\n",
      "Mean Reward: 23.6 ± 7.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 930/3906\n",
      "Global Step: 119040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 930/3906, Global Timesteps: 119040\n",
      "\n",
      "--- Evaluation after Update 940 ---\n",
      "Total Timesteps: 120320\n",
      "Mean Reward: 24.1 ± 4.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 940/3906\n",
      "Global Step: 120320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 940/3906, Global Timesteps: 120320\n",
      "\n",
      "--- Evaluation after Update 950 ---\n",
      "Total Timesteps: 121600\n",
      "Mean Reward: 24.5 ± 2.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 950/3906\n",
      "Global Step: 121600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 950/3906, Global Timesteps: 121600\n",
      "\n",
      "--- Evaluation after Update 960 ---\n",
      "Total Timesteps: 122880\n",
      "Mean Reward: 24.6 ± 6.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 960/3906\n",
      "Global Step: 122880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 960/3906, Global Timesteps: 122880\n",
      "\n",
      "--- Evaluation after Update 970 ---\n",
      "Total Timesteps: 124160\n",
      "Mean Reward: 23.0 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 970/3906\n",
      "Global Step: 124160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 970/3906, Global Timesteps: 124160\n",
      "\n",
      "--- Evaluation after Update 980 ---\n",
      "Total Timesteps: 125440\n",
      "Mean Reward: 26.4 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 980/3906\n",
      "Global Step: 125440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 980/3906, Global Timesteps: 125440\n",
      "\n",
      "--- Evaluation after Update 990 ---\n",
      "Total Timesteps: 126720\n",
      "Mean Reward: 24.3 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 990/3906\n",
      "Global Step: 126720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 990/3906, Global Timesteps: 126720\n",
      "\n",
      "--- Evaluation after Update 1000 ---\n",
      "Total Timesteps: 128000\n",
      "Mean Reward: 28.4 ± 7.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1000/3906\n",
      "Global Step: 128000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1000/3906, Global Timesteps: 128000\n",
      "\n",
      "--- Evaluation after Update 1010 ---\n",
      "Total Timesteps: 129280\n",
      "Mean Reward: 24.8 ± 6.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1010/3906\n",
      "Global Step: 129280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1010/3906, Global Timesteps: 129280\n",
      "\n",
      "--- Evaluation after Update 1020 ---\n",
      "Total Timesteps: 130560\n",
      "Mean Reward: 23.6 ± 5.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1020/3906\n",
      "Global Step: 130560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1020/3906, Global Timesteps: 130560\n",
      "\n",
      "--- Evaluation after Update 1030 ---\n",
      "Total Timesteps: 131840\n",
      "Mean Reward: 23.6 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1030/3906\n",
      "Global Step: 131840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1030/3906, Global Timesteps: 131840\n",
      "\n",
      "--- Evaluation after Update 1040 ---\n",
      "Total Timesteps: 133120\n",
      "Mean Reward: 25.1 ± 4.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1040/3906\n",
      "Global Step: 133120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1040/3906, Global Timesteps: 133120\n",
      "\n",
      "--- Evaluation after Update 1050 ---\n",
      "Total Timesteps: 134400\n",
      "Mean Reward: 25.7 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1050/3906\n",
      "Global Step: 134400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1050/3906, Global Timesteps: 134400\n",
      "\n",
      "--- Evaluation after Update 1060 ---\n",
      "Total Timesteps: 135680\n",
      "Mean Reward: 22.2 ± 7.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1060/3906\n",
      "Global Step: 135680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1060/3906, Global Timesteps: 135680\n",
      "\n",
      "--- Evaluation after Update 1070 ---\n",
      "Total Timesteps: 136960\n",
      "Mean Reward: 19.9 ± 3.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1070/3906\n",
      "Global Step: 136960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1070/3906, Global Timesteps: 136960\n",
      "\n",
      "--- Evaluation after Update 1080 ---\n",
      "Total Timesteps: 138240\n",
      "Mean Reward: 18.8 ± 6.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1080/3906\n",
      "Global Step: 138240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1080/3906, Global Timesteps: 138240\n",
      "\n",
      "--- Evaluation after Update 1090 ---\n",
      "Total Timesteps: 139520\n",
      "Mean Reward: 23.5 ± 4.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1090/3906\n",
      "Global Step: 139520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1090/3906, Global Timesteps: 139520\n",
      "\n",
      "--- Evaluation after Update 1100 ---\n",
      "Total Timesteps: 140800\n",
      "Mean Reward: 22.0 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1100/3906\n",
      "Global Step: 140800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1100/3906, Global Timesteps: 140800\n",
      "\n",
      "--- Evaluation after Update 1110 ---\n",
      "Total Timesteps: 142080\n",
      "Mean Reward: 21.9 ± 2.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1110/3906\n",
      "Global Step: 142080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1110/3906, Global Timesteps: 142080\n",
      "\n",
      "--- Evaluation after Update 1120 ---\n",
      "Total Timesteps: 143360\n",
      "Mean Reward: 26.7 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1120/3906\n",
      "Global Step: 143360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1120/3906, Global Timesteps: 143360\n",
      "\n",
      "--- Evaluation after Update 1130 ---\n",
      "Total Timesteps: 144640\n",
      "Mean Reward: 24.8 ± 5.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1130/3906\n",
      "Global Step: 144640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1130/3906, Global Timesteps: 144640\n",
      "\n",
      "--- Evaluation after Update 1140 ---\n",
      "Total Timesteps: 145920\n",
      "Mean Reward: 24.6 ± 3.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1140/3906\n",
      "Global Step: 145920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1140/3906, Global Timesteps: 145920\n",
      "\n",
      "--- Evaluation after Update 1150 ---\n",
      "Total Timesteps: 147200\n",
      "Mean Reward: 22.8 ± 6.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1150/3906\n",
      "Global Step: 147200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1150/3906, Global Timesteps: 147200\n",
      "\n",
      "--- Evaluation after Update 1160 ---\n",
      "Total Timesteps: 148480\n",
      "Mean Reward: 24.0 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1160/3906\n",
      "Global Step: 148480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1160/3906, Global Timesteps: 148480\n",
      "\n",
      "--- Evaluation after Update 1170 ---\n",
      "Total Timesteps: 149760\n",
      "Mean Reward: 26.4 ± 4.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1170/3906\n",
      "Global Step: 149760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1170/3906, Global Timesteps: 149760\n",
      "\n",
      "--- Evaluation after Update 1180 ---\n",
      "Total Timesteps: 151040\n",
      "Mean Reward: 23.1 ± 6.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1180/3906\n",
      "Global Step: 151040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1180/3906, Global Timesteps: 151040\n",
      "\n",
      "--- Evaluation after Update 1190 ---\n",
      "Total Timesteps: 152320\n",
      "Mean Reward: 23.7 ± 6.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1190/3906\n",
      "Global Step: 152320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1190/3906, Global Timesteps: 152320\n",
      "\n",
      "--- Evaluation after Update 1200 ---\n",
      "Total Timesteps: 153600\n",
      "Mean Reward: 21.9 ± 6.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1200/3906\n",
      "Global Step: 153600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1200/3906, Global Timesteps: 153600\n",
      "\n",
      "--- Evaluation after Update 1210 ---\n",
      "Total Timesteps: 154880\n",
      "Mean Reward: 21.4 ± 7.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1210/3906\n",
      "Global Step: 154880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1210/3906, Global Timesteps: 154880\n",
      "\n",
      "--- Evaluation after Update 1220 ---\n",
      "Total Timesteps: 156160\n",
      "Mean Reward: 26.4 ± 6.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1220/3906\n",
      "Global Step: 156160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1220/3906, Global Timesteps: 156160\n",
      "\n",
      "--- Evaluation after Update 1230 ---\n",
      "Total Timesteps: 157440\n",
      "Mean Reward: 25.6 ± 4.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1230/3906\n",
      "Global Step: 157440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1230/3906, Global Timesteps: 157440\n",
      "\n",
      "--- Evaluation after Update 1240 ---\n",
      "Total Timesteps: 158720\n",
      "Mean Reward: 26.4 ± 5.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1240/3906\n",
      "Global Step: 158720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1240/3906, Global Timesteps: 158720\n",
      "\n",
      "--- Evaluation after Update 1250 ---\n",
      "Total Timesteps: 160000\n",
      "Mean Reward: 27.0 ± 6.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1250/3906\n",
      "Global Step: 160000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1250/3906, Global Timesteps: 160000\n",
      "\n",
      "--- Evaluation after Update 1260 ---\n",
      "Total Timesteps: 161280\n",
      "Mean Reward: 24.4 ± 8.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1260/3906\n",
      "Global Step: 161280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1260/3906, Global Timesteps: 161280\n",
      "\n",
      "--- Evaluation after Update 1270 ---\n",
      "Total Timesteps: 162560\n",
      "Mean Reward: 19.1 ± 6.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1270/3906\n",
      "Global Step: 162560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1270/3906, Global Timesteps: 162560\n",
      "\n",
      "--- Evaluation after Update 1280 ---\n",
      "Total Timesteps: 163840\n",
      "Mean Reward: 21.5 ± 3.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1280/3906\n",
      "Global Step: 163840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1280/3906, Global Timesteps: 163840\n",
      "\n",
      "--- Evaluation after Update 1290 ---\n",
      "Total Timesteps: 165120\n",
      "Mean Reward: 24.3 ± 4.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1290/3906\n",
      "Global Step: 165120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1290/3906, Global Timesteps: 165120\n",
      "\n",
      "--- Evaluation after Update 1300 ---\n",
      "Total Timesteps: 166400\n",
      "Mean Reward: 25.2 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1300/3906\n",
      "Global Step: 166400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1300/3906, Global Timesteps: 166400\n",
      "\n",
      "--- Evaluation after Update 1310 ---\n",
      "Total Timesteps: 167680\n",
      "Mean Reward: 26.5 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1310/3906\n",
      "Global Step: 167680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1310/3906, Global Timesteps: 167680\n",
      "\n",
      "--- Evaluation after Update 1320 ---\n",
      "Total Timesteps: 168960\n",
      "Mean Reward: 25.1 ± 5.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1320/3906\n",
      "Global Step: 168960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1320/3906, Global Timesteps: 168960\n",
      "\n",
      "--- Evaluation after Update 1330 ---\n",
      "Total Timesteps: 170240\n",
      "Mean Reward: 25.6 ± 4.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1330/3906\n",
      "Global Step: 170240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1330/3906, Global Timesteps: 170240\n",
      "\n",
      "--- Evaluation after Update 1340 ---\n",
      "Total Timesteps: 171520\n",
      "Mean Reward: 23.6 ± 6.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1340/3906\n",
      "Global Step: 171520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1340/3906, Global Timesteps: 171520\n",
      "\n",
      "--- Evaluation after Update 1350 ---\n",
      "Total Timesteps: 172800\n",
      "Mean Reward: 24.1 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1350/3906\n",
      "Global Step: 172800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1350/3906, Global Timesteps: 172800\n",
      "\n",
      "--- Evaluation after Update 1360 ---\n",
      "Total Timesteps: 174080\n",
      "Mean Reward: 23.9 ± 6.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1360/3906\n",
      "Global Step: 174080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1360/3906, Global Timesteps: 174080\n",
      "\n",
      "--- Evaluation after Update 1370 ---\n",
      "Total Timesteps: 175360\n",
      "Mean Reward: 25.5 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1370/3906\n",
      "Global Step: 175360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1370/3906, Global Timesteps: 175360\n",
      "\n",
      "--- Evaluation after Update 1380 ---\n",
      "Total Timesteps: 176640\n",
      "Mean Reward: 21.9 ± 7.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1380/3906\n",
      "Global Step: 176640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1380/3906, Global Timesteps: 176640\n",
      "\n",
      "--- Evaluation after Update 1390 ---\n",
      "Total Timesteps: 177920\n",
      "Mean Reward: 23.2 ± 5.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1390/3906\n",
      "Global Step: 177920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1390/3906, Global Timesteps: 177920\n",
      "\n",
      "--- Evaluation after Update 1400 ---\n",
      "Total Timesteps: 179200\n",
      "Mean Reward: 26.7 ± 7.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1400/3906\n",
      "Global Step: 179200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1400/3906, Global Timesteps: 179200\n",
      "\n",
      "--- Evaluation after Update 1410 ---\n",
      "Total Timesteps: 180480\n",
      "Mean Reward: 25.5 ± 3.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1410/3906\n",
      "Global Step: 180480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1410/3906, Global Timesteps: 180480\n",
      "\n",
      "--- Evaluation after Update 1420 ---\n",
      "Total Timesteps: 181760\n",
      "Mean Reward: 24.6 ± 6.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1420/3906\n",
      "Global Step: 181760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1420/3906, Global Timesteps: 181760\n",
      "\n",
      "--- Evaluation after Update 1430 ---\n",
      "Total Timesteps: 183040\n",
      "Mean Reward: 24.5 ± 5.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1430/3906\n",
      "Global Step: 183040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1430/3906, Global Timesteps: 183040\n",
      "\n",
      "--- Evaluation after Update 1440 ---\n",
      "Total Timesteps: 184320\n",
      "Mean Reward: 22.6 ± 3.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1440/3906\n",
      "Global Step: 184320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1440/3906, Global Timesteps: 184320\n",
      "\n",
      "--- Evaluation after Update 1450 ---\n",
      "Total Timesteps: 185600\n",
      "Mean Reward: 25.0 ± 2.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1450/3906\n",
      "Global Step: 185600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1450/3906, Global Timesteps: 185600\n",
      "\n",
      "--- Evaluation after Update 1460 ---\n",
      "Total Timesteps: 186880\n",
      "Mean Reward: 22.1 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1460/3906\n",
      "Global Step: 186880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1460/3906, Global Timesteps: 186880\n",
      "\n",
      "--- Evaluation after Update 1470 ---\n",
      "Total Timesteps: 188160\n",
      "Mean Reward: 25.0 ± 5.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1470/3906\n",
      "Global Step: 188160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1470/3906, Global Timesteps: 188160\n",
      "\n",
      "--- Evaluation after Update 1480 ---\n",
      "Total Timesteps: 189440\n",
      "Mean Reward: 24.6 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1480/3906\n",
      "Global Step: 189440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1480/3906, Global Timesteps: 189440\n",
      "\n",
      "--- Evaluation after Update 1490 ---\n",
      "Total Timesteps: 190720\n",
      "Mean Reward: 23.1 ± 5.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1490/3906\n",
      "Global Step: 190720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1490/3906, Global Timesteps: 190720\n",
      "\n",
      "--- Evaluation after Update 1500 ---\n",
      "Total Timesteps: 192000\n",
      "Mean Reward: 24.2 ± 6.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1500/3906\n",
      "Global Step: 192000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1500/3906, Global Timesteps: 192000\n",
      "\n",
      "--- Evaluation after Update 1510 ---\n",
      "Total Timesteps: 193280\n",
      "Mean Reward: 25.8 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1510/3906\n",
      "Global Step: 193280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1510/3906, Global Timesteps: 193280\n",
      "\n",
      "--- Evaluation after Update 1520 ---\n",
      "Total Timesteps: 194560\n",
      "Mean Reward: 25.6 ± 6.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1520/3906\n",
      "Global Step: 194560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1520/3906, Global Timesteps: 194560\n",
      "\n",
      "--- Evaluation after Update 1530 ---\n",
      "Total Timesteps: 195840\n",
      "Mean Reward: 22.7 ± 7.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1530/3906\n",
      "Global Step: 195840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1530/3906, Global Timesteps: 195840\n",
      "\n",
      "--- Evaluation after Update 1540 ---\n",
      "Total Timesteps: 197120\n",
      "Mean Reward: 24.3 ± 4.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1540/3906\n",
      "Global Step: 197120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1540/3906, Global Timesteps: 197120\n",
      "\n",
      "--- Evaluation after Update 1550 ---\n",
      "Total Timesteps: 198400\n",
      "Mean Reward: 25.5 ± 3.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1550/3906\n",
      "Global Step: 198400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1550/3906, Global Timesteps: 198400\n",
      "\n",
      "--- Evaluation after Update 1560 ---\n",
      "Total Timesteps: 199680\n",
      "Mean Reward: 26.0 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1560/3906\n",
      "Global Step: 199680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1560/3906, Global Timesteps: 199680\n",
      "\n",
      "--- Evaluation after Update 1570 ---\n",
      "Total Timesteps: 200960\n",
      "Mean Reward: 25.5 ± 4.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1570/3906\n",
      "Global Step: 200960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1570/3906, Global Timesteps: 200960\n",
      "\n",
      "--- Evaluation after Update 1580 ---\n",
      "Total Timesteps: 202240\n",
      "Mean Reward: 24.9 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1580/3906\n",
      "Global Step: 202240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1580/3906, Global Timesteps: 202240\n",
      "\n",
      "--- Evaluation after Update 1590 ---\n",
      "Total Timesteps: 203520\n",
      "Mean Reward: 24.1 ± 3.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1590/3906\n",
      "Global Step: 203520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1590/3906, Global Timesteps: 203520\n",
      "\n",
      "--- Evaluation after Update 1600 ---\n",
      "Total Timesteps: 204800\n",
      "Mean Reward: 24.7 ± 7.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1600/3906\n",
      "Global Step: 204800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1600/3906, Global Timesteps: 204800\n",
      "\n",
      "--- Evaluation after Update 1610 ---\n",
      "Total Timesteps: 206080\n",
      "Mean Reward: 25.4 ± 4.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1610/3906\n",
      "Global Step: 206080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1610/3906, Global Timesteps: 206080\n",
      "\n",
      "--- Evaluation after Update 1620 ---\n",
      "Total Timesteps: 207360\n",
      "Mean Reward: 22.3 ± 5.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1620/3906\n",
      "Global Step: 207360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1620/3906, Global Timesteps: 207360\n",
      "\n",
      "--- Evaluation after Update 1630 ---\n",
      "Total Timesteps: 208640\n",
      "Mean Reward: 22.7 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1630/3906\n",
      "Global Step: 208640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1630/3906, Global Timesteps: 208640\n",
      "\n",
      "--- Evaluation after Update 1640 ---\n",
      "Total Timesteps: 209920\n",
      "Mean Reward: 25.7 ± 3.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1640/3906\n",
      "Global Step: 209920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1640/3906, Global Timesteps: 209920\n",
      "\n",
      "--- Evaluation after Update 1650 ---\n",
      "Total Timesteps: 211200\n",
      "Mean Reward: 26.9 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1650/3906\n",
      "Global Step: 211200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1650/3906, Global Timesteps: 211200\n",
      "\n",
      "--- Evaluation after Update 1660 ---\n",
      "Total Timesteps: 212480\n",
      "Mean Reward: 25.1 ± 6.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1660/3906\n",
      "Global Step: 212480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1660/3906, Global Timesteps: 212480\n",
      "\n",
      "--- Evaluation after Update 1670 ---\n",
      "Total Timesteps: 213760\n",
      "Mean Reward: 26.1 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1670/3906\n",
      "Global Step: 213760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1670/3906, Global Timesteps: 213760\n",
      "\n",
      "--- Evaluation after Update 1680 ---\n",
      "Total Timesteps: 215040\n",
      "Mean Reward: 25.6 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1680/3906\n",
      "Global Step: 215040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1680/3906, Global Timesteps: 215040\n",
      "\n",
      "--- Evaluation after Update 1690 ---\n",
      "Total Timesteps: 216320\n",
      "Mean Reward: 24.4 ± 4.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1690/3906\n",
      "Global Step: 216320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1690/3906, Global Timesteps: 216320\n",
      "\n",
      "--- Evaluation after Update 1700 ---\n",
      "Total Timesteps: 217600\n",
      "Mean Reward: 22.6 ± 4.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1700/3906\n",
      "Global Step: 217600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1700/3906, Global Timesteps: 217600\n",
      "\n",
      "--- Evaluation after Update 1710 ---\n",
      "Total Timesteps: 218880\n",
      "Mean Reward: 24.9 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1710/3906\n",
      "Global Step: 218880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1710/3906, Global Timesteps: 218880\n",
      "\n",
      "--- Evaluation after Update 1720 ---\n",
      "Total Timesteps: 220160\n",
      "Mean Reward: 21.2 ± 6.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1720/3906\n",
      "Global Step: 220160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1720/3906, Global Timesteps: 220160\n",
      "\n",
      "--- Evaluation after Update 1730 ---\n",
      "Total Timesteps: 221440\n",
      "Mean Reward: 24.6 ± 6.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1730/3906\n",
      "Global Step: 221440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1730/3906, Global Timesteps: 221440\n",
      "\n",
      "--- Evaluation after Update 1740 ---\n",
      "Total Timesteps: 222720\n",
      "Mean Reward: 24.6 ± 4.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1740/3906\n",
      "Global Step: 222720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1740/3906, Global Timesteps: 222720\n",
      "\n",
      "--- Evaluation after Update 1750 ---\n",
      "Total Timesteps: 224000\n",
      "Mean Reward: 25.3 ± 5.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1750/3906\n",
      "Global Step: 224000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1750/3906, Global Timesteps: 224000\n",
      "\n",
      "--- Evaluation after Update 1760 ---\n",
      "Total Timesteps: 225280\n",
      "Mean Reward: 25.0 ± 3.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1760/3906\n",
      "Global Step: 225280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1760/3906, Global Timesteps: 225280\n",
      "\n",
      "--- Evaluation after Update 1770 ---\n",
      "Total Timesteps: 226560\n",
      "Mean Reward: 23.8 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1770/3906\n",
      "Global Step: 226560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1770/3906, Global Timesteps: 226560\n",
      "\n",
      "--- Evaluation after Update 1780 ---\n",
      "Total Timesteps: 227840\n",
      "Mean Reward: 22.4 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1780/3906\n",
      "Global Step: 227840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1780/3906, Global Timesteps: 227840\n",
      "\n",
      "--- Evaluation after Update 1790 ---\n",
      "Total Timesteps: 229120\n",
      "Mean Reward: 24.9 ± 4.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1790/3906\n",
      "Global Step: 229120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1790/3906, Global Timesteps: 229120\n",
      "\n",
      "--- Evaluation after Update 1800 ---\n",
      "Total Timesteps: 230400\n",
      "Mean Reward: 22.4 ± 6.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1800/3906\n",
      "Global Step: 230400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1800/3906, Global Timesteps: 230400\n",
      "\n",
      "--- Evaluation after Update 1810 ---\n",
      "Total Timesteps: 231680\n",
      "Mean Reward: 21.4 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1810/3906\n",
      "Global Step: 231680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1810/3906, Global Timesteps: 231680\n",
      "\n",
      "--- Evaluation after Update 1820 ---\n",
      "Total Timesteps: 232960\n",
      "Mean Reward: 23.0 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1820/3906\n",
      "Global Step: 232960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1820/3906, Global Timesteps: 232960\n",
      "\n",
      "--- Evaluation after Update 1830 ---\n",
      "Total Timesteps: 234240\n",
      "Mean Reward: 23.7 ± 4.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1830/3906\n",
      "Global Step: 234240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1830/3906, Global Timesteps: 234240\n",
      "\n",
      "--- Evaluation after Update 1840 ---\n",
      "Total Timesteps: 235520\n",
      "Mean Reward: 22.2 ± 6.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1840/3906\n",
      "Global Step: 235520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1840/3906, Global Timesteps: 235520\n",
      "\n",
      "--- Evaluation after Update 1850 ---\n",
      "Total Timesteps: 236800\n",
      "Mean Reward: 23.8 ± 6.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1850/3906\n",
      "Global Step: 236800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1850/3906, Global Timesteps: 236800\n",
      "\n",
      "--- Evaluation after Update 1860 ---\n",
      "Total Timesteps: 238080\n",
      "Mean Reward: 21.3 ± 4.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1860/3906\n",
      "Global Step: 238080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1860/3906, Global Timesteps: 238080\n",
      "\n",
      "--- Evaluation after Update 1870 ---\n",
      "Total Timesteps: 239360\n",
      "Mean Reward: 22.9 ± 2.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1870/3906\n",
      "Global Step: 239360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1870/3906, Global Timesteps: 239360\n",
      "\n",
      "--- Evaluation after Update 1880 ---\n",
      "Total Timesteps: 240640\n",
      "Mean Reward: 23.5 ± 2.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1880/3906\n",
      "Global Step: 240640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1880/3906, Global Timesteps: 240640\n",
      "\n",
      "--- Evaluation after Update 1890 ---\n",
      "Total Timesteps: 241920\n",
      "Mean Reward: 25.3 ± 3.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1890/3906\n",
      "Global Step: 241920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1890/3906, Global Timesteps: 241920\n",
      "\n",
      "--- Evaluation after Update 1900 ---\n",
      "Total Timesteps: 243200\n",
      "Mean Reward: 20.3 ± 3.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1900/3906\n",
      "Global Step: 243200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1900/3906, Global Timesteps: 243200\n",
      "\n",
      "--- Evaluation after Update 1910 ---\n",
      "Total Timesteps: 244480\n",
      "Mean Reward: 24.0 ± 6.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1910/3906\n",
      "Global Step: 244480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1910/3906, Global Timesteps: 244480\n",
      "\n",
      "--- Evaluation after Update 1920 ---\n",
      "Total Timesteps: 245760\n",
      "Mean Reward: 24.1 ± 5.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1920/3906\n",
      "Global Step: 245760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1920/3906, Global Timesteps: 245760\n",
      "\n",
      "--- Evaluation after Update 1930 ---\n",
      "Total Timesteps: 247040\n",
      "Mean Reward: 23.4 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1930/3906\n",
      "Global Step: 247040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1930/3906, Global Timesteps: 247040\n",
      "\n",
      "--- Evaluation after Update 1940 ---\n",
      "Total Timesteps: 248320\n",
      "Mean Reward: 26.0 ± 6.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1940/3906\n",
      "Global Step: 248320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1940/3906, Global Timesteps: 248320\n",
      "\n",
      "--- Evaluation after Update 1950 ---\n",
      "Total Timesteps: 249600\n",
      "Mean Reward: 22.3 ± 6.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1950/3906\n",
      "Global Step: 249600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1950/3906, Global Timesteps: 249600\n",
      "\n",
      "--- Evaluation after Update 1960 ---\n",
      "Total Timesteps: 250880\n",
      "Mean Reward: 24.2 ± 3.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1960/3906\n",
      "Global Step: 250880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1960/3906, Global Timesteps: 250880\n",
      "\n",
      "--- Evaluation after Update 1970 ---\n",
      "Total Timesteps: 252160\n",
      "Mean Reward: 27.0 ± 5.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1970/3906\n",
      "Global Step: 252160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1970/3906, Global Timesteps: 252160\n",
      "\n",
      "--- Evaluation after Update 1980 ---\n",
      "Total Timesteps: 253440\n",
      "Mean Reward: 23.9 ± 7.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1980/3906\n",
      "Global Step: 253440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1980/3906, Global Timesteps: 253440\n",
      "\n",
      "--- Evaluation after Update 1990 ---\n",
      "Total Timesteps: 254720\n",
      "Mean Reward: 22.0 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 1990/3906\n",
      "Global Step: 254720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 1990/3906, Global Timesteps: 254720\n",
      "\n",
      "--- Evaluation after Update 2000 ---\n",
      "Total Timesteps: 256000\n",
      "Mean Reward: 23.1 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2000/3906\n",
      "Global Step: 256000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2000/3906, Global Timesteps: 256000\n",
      "\n",
      "--- Evaluation after Update 2010 ---\n",
      "Total Timesteps: 257280\n",
      "Mean Reward: 23.5 ± 6.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2010/3906\n",
      "Global Step: 257280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2010/3906, Global Timesteps: 257280\n",
      "\n",
      "--- Evaluation after Update 2020 ---\n",
      "Total Timesteps: 258560\n",
      "Mean Reward: 21.3 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2020/3906\n",
      "Global Step: 258560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2020/3906, Global Timesteps: 258560\n",
      "\n",
      "--- Evaluation after Update 2030 ---\n",
      "Total Timesteps: 259840\n",
      "Mean Reward: 23.5 ± 5.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2030/3906\n",
      "Global Step: 259840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2030/3906, Global Timesteps: 259840\n",
      "\n",
      "--- Evaluation after Update 2040 ---\n",
      "Total Timesteps: 261120\n",
      "Mean Reward: 24.2 ± 4.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2040/3906\n",
      "Global Step: 261120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2040/3906, Global Timesteps: 261120\n",
      "\n",
      "--- Evaluation after Update 2050 ---\n",
      "Total Timesteps: 262400\n",
      "Mean Reward: 23.5 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2050/3906\n",
      "Global Step: 262400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2050/3906, Global Timesteps: 262400\n",
      "\n",
      "--- Evaluation after Update 2060 ---\n",
      "Total Timesteps: 263680\n",
      "Mean Reward: 24.0 ± 4.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2060/3906\n",
      "Global Step: 263680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2060/3906, Global Timesteps: 263680\n",
      "\n",
      "--- Evaluation after Update 2070 ---\n",
      "Total Timesteps: 264960\n",
      "Mean Reward: 23.5 ± 3.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2070/3906\n",
      "Global Step: 264960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2070/3906, Global Timesteps: 264960\n",
      "\n",
      "--- Evaluation after Update 2080 ---\n",
      "Total Timesteps: 266240\n",
      "Mean Reward: 25.5 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2080/3906\n",
      "Global Step: 266240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2080/3906, Global Timesteps: 266240\n",
      "\n",
      "--- Evaluation after Update 2090 ---\n",
      "Total Timesteps: 267520\n",
      "Mean Reward: 25.1 ± 5.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2090/3906\n",
      "Global Step: 267520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2090/3906, Global Timesteps: 267520\n",
      "\n",
      "--- Evaluation after Update 2100 ---\n",
      "Total Timesteps: 268800\n",
      "Mean Reward: 22.9 ± 5.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2100/3906\n",
      "Global Step: 268800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2100/3906, Global Timesteps: 268800\n",
      "\n",
      "--- Evaluation after Update 2110 ---\n",
      "Total Timesteps: 270080\n",
      "Mean Reward: 25.4 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2110/3906\n",
      "Global Step: 270080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2110/3906, Global Timesteps: 270080\n",
      "\n",
      "--- Evaluation after Update 2120 ---\n",
      "Total Timesteps: 271360\n",
      "Mean Reward: 22.7 ± 3.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2120/3906\n",
      "Global Step: 271360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2120/3906, Global Timesteps: 271360\n",
      "\n",
      "--- Evaluation after Update 2130 ---\n",
      "Total Timesteps: 272640\n",
      "Mean Reward: 20.2 ± 4.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2130/3906\n",
      "Global Step: 272640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2130/3906, Global Timesteps: 272640\n",
      "\n",
      "--- Evaluation after Update 2140 ---\n",
      "Total Timesteps: 273920\n",
      "Mean Reward: 22.0 ± 3.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2140/3906\n",
      "Global Step: 273920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2140/3906, Global Timesteps: 273920\n",
      "\n",
      "--- Evaluation after Update 2150 ---\n",
      "Total Timesteps: 275200\n",
      "Mean Reward: 25.6 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2150/3906\n",
      "Global Step: 275200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2150/3906, Global Timesteps: 275200\n",
      "\n",
      "--- Evaluation after Update 2160 ---\n",
      "Total Timesteps: 276480\n",
      "Mean Reward: 24.6 ± 4.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2160/3906\n",
      "Global Step: 276480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2160/3906, Global Timesteps: 276480\n",
      "\n",
      "--- Evaluation after Update 2170 ---\n",
      "Total Timesteps: 277760\n",
      "Mean Reward: 27.0 ± 9.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2170/3906\n",
      "Global Step: 277760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2170/3906, Global Timesteps: 277760\n",
      "\n",
      "--- Evaluation after Update 2180 ---\n",
      "Total Timesteps: 279040\n",
      "Mean Reward: 26.8 ± 6.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2180/3906\n",
      "Global Step: 279040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2180/3906, Global Timesteps: 279040\n",
      "\n",
      "--- Evaluation after Update 2190 ---\n",
      "Total Timesteps: 280320\n",
      "Mean Reward: 25.6 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2190/3906\n",
      "Global Step: 280320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2190/3906, Global Timesteps: 280320\n",
      "\n",
      "--- Evaluation after Update 2200 ---\n",
      "Total Timesteps: 281600\n",
      "Mean Reward: 20.6 ± 4.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2200/3906\n",
      "Global Step: 281600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2200/3906, Global Timesteps: 281600\n",
      "\n",
      "--- Evaluation after Update 2210 ---\n",
      "Total Timesteps: 282880\n",
      "Mean Reward: 22.8 ± 6.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2210/3906\n",
      "Global Step: 282880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2210/3906, Global Timesteps: 282880\n",
      "\n",
      "--- Evaluation after Update 2220 ---\n",
      "Total Timesteps: 284160\n",
      "Mean Reward: 23.1 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2220/3906\n",
      "Global Step: 284160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2220/3906, Global Timesteps: 284160\n",
      "\n",
      "--- Evaluation after Update 2230 ---\n",
      "Total Timesteps: 285440\n",
      "Mean Reward: 22.3 ± 4.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2230/3906\n",
      "Global Step: 285440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2230/3906, Global Timesteps: 285440\n",
      "\n",
      "--- Evaluation after Update 2240 ---\n",
      "Total Timesteps: 286720\n",
      "Mean Reward: 25.4 ± 6.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2240/3906\n",
      "Global Step: 286720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2240/3906, Global Timesteps: 286720\n",
      "\n",
      "--- Evaluation after Update 2250 ---\n",
      "Total Timesteps: 288000\n",
      "Mean Reward: 25.3 ± 4.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2250/3906\n",
      "Global Step: 288000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2250/3906, Global Timesteps: 288000\n",
      "\n",
      "--- Evaluation after Update 2260 ---\n",
      "Total Timesteps: 289280\n",
      "Mean Reward: 25.2 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2260/3906\n",
      "Global Step: 289280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2260/3906, Global Timesteps: 289280\n",
      "\n",
      "--- Evaluation after Update 2270 ---\n",
      "Total Timesteps: 290560\n",
      "Mean Reward: 22.1 ± 5.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2270/3906\n",
      "Global Step: 290560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2270/3906, Global Timesteps: 290560\n",
      "\n",
      "--- Evaluation after Update 2280 ---\n",
      "Total Timesteps: 291840\n",
      "Mean Reward: 24.7 ± 4.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2280/3906\n",
      "Global Step: 291840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2280/3906, Global Timesteps: 291840\n",
      "\n",
      "--- Evaluation after Update 2290 ---\n",
      "Total Timesteps: 293120\n",
      "Mean Reward: 24.3 ± 2.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2290/3906\n",
      "Global Step: 293120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2290/3906, Global Timesteps: 293120\n",
      "\n",
      "--- Evaluation after Update 2300 ---\n",
      "Total Timesteps: 294400\n",
      "Mean Reward: 22.8 ± 6.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2300/3906\n",
      "Global Step: 294400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2300/3906, Global Timesteps: 294400\n",
      "\n",
      "--- Evaluation after Update 2310 ---\n",
      "Total Timesteps: 295680\n",
      "Mean Reward: 21.8 ± 6.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2310/3906\n",
      "Global Step: 295680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2310/3906, Global Timesteps: 295680\n",
      "\n",
      "--- Evaluation after Update 2320 ---\n",
      "Total Timesteps: 296960\n",
      "Mean Reward: 25.1 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2320/3906\n",
      "Global Step: 296960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2320/3906, Global Timesteps: 296960\n",
      "\n",
      "--- Evaluation after Update 2330 ---\n",
      "Total Timesteps: 298240\n",
      "Mean Reward: 26.5 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2330/3906\n",
      "Global Step: 298240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2330/3906, Global Timesteps: 298240\n",
      "\n",
      "--- Evaluation after Update 2340 ---\n",
      "Total Timesteps: 299520\n",
      "Mean Reward: 23.0 ± 3.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2340/3906\n",
      "Global Step: 299520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2340/3906, Global Timesteps: 299520\n",
      "\n",
      "--- Evaluation after Update 2350 ---\n",
      "Total Timesteps: 300800\n",
      "Mean Reward: 25.5 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2350/3906\n",
      "Global Step: 300800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2350/3906, Global Timesteps: 300800\n",
      "\n",
      "--- Evaluation after Update 2360 ---\n",
      "Total Timesteps: 302080\n",
      "Mean Reward: 25.6 ± 3.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2360/3906\n",
      "Global Step: 302080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2360/3906, Global Timesteps: 302080\n",
      "\n",
      "--- Evaluation after Update 2370 ---\n",
      "Total Timesteps: 303360\n",
      "Mean Reward: 22.8 ± 5.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2370/3906\n",
      "Global Step: 303360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2370/3906, Global Timesteps: 303360\n",
      "\n",
      "--- Evaluation after Update 2380 ---\n",
      "Total Timesteps: 304640\n",
      "Mean Reward: 24.8 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2380/3906\n",
      "Global Step: 304640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2380/3906, Global Timesteps: 304640\n",
      "\n",
      "--- Evaluation after Update 2390 ---\n",
      "Total Timesteps: 305920\n",
      "Mean Reward: 22.9 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2390/3906\n",
      "Global Step: 305920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2390/3906, Global Timesteps: 305920\n",
      "\n",
      "--- Evaluation after Update 2400 ---\n",
      "Total Timesteps: 307200\n",
      "Mean Reward: 23.1 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2400/3906\n",
      "Global Step: 307200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2400/3906, Global Timesteps: 307200\n",
      "\n",
      "--- Evaluation after Update 2410 ---\n",
      "Total Timesteps: 308480\n",
      "Mean Reward: 22.9 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2410/3906\n",
      "Global Step: 308480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2410/3906, Global Timesteps: 308480\n",
      "\n",
      "--- Evaluation after Update 2420 ---\n",
      "Total Timesteps: 309760\n",
      "Mean Reward: 22.0 ± 3.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2420/3906\n",
      "Global Step: 309760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2420/3906, Global Timesteps: 309760\n",
      "\n",
      "--- Evaluation after Update 2430 ---\n",
      "Total Timesteps: 311040\n",
      "Mean Reward: 25.8 ± 6.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2430/3906\n",
      "Global Step: 311040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2430/3906, Global Timesteps: 311040\n",
      "\n",
      "--- Evaluation after Update 2440 ---\n",
      "Total Timesteps: 312320\n",
      "Mean Reward: 24.8 ± 5.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2440/3906\n",
      "Global Step: 312320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2440/3906, Global Timesteps: 312320\n",
      "\n",
      "--- Evaluation after Update 2450 ---\n",
      "Total Timesteps: 313600\n",
      "Mean Reward: 23.2 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2450/3906\n",
      "Global Step: 313600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2450/3906, Global Timesteps: 313600\n",
      "\n",
      "--- Evaluation after Update 2460 ---\n",
      "Total Timesteps: 314880\n",
      "Mean Reward: 24.1 ± 5.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2460/3906\n",
      "Global Step: 314880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2460/3906, Global Timesteps: 314880\n",
      "\n",
      "--- Evaluation after Update 2470 ---\n",
      "Total Timesteps: 316160\n",
      "Mean Reward: 24.3 ± 3.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2470/3906\n",
      "Global Step: 316160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2470/3906, Global Timesteps: 316160\n",
      "\n",
      "--- Evaluation after Update 2480 ---\n",
      "Total Timesteps: 317440\n",
      "Mean Reward: 20.3 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2480/3906\n",
      "Global Step: 317440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2480/3906, Global Timesteps: 317440\n",
      "\n",
      "--- Evaluation after Update 2490 ---\n",
      "Total Timesteps: 318720\n",
      "Mean Reward: 25.6 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2490/3906\n",
      "Global Step: 318720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2490/3906, Global Timesteps: 318720\n",
      "\n",
      "--- Evaluation after Update 2500 ---\n",
      "Total Timesteps: 320000\n",
      "Mean Reward: 24.8 ± 4.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2500/3906\n",
      "Global Step: 320000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2500/3906, Global Timesteps: 320000\n",
      "\n",
      "--- Evaluation after Update 2510 ---\n",
      "Total Timesteps: 321280\n",
      "Mean Reward: 24.9 ± 6.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2510/3906\n",
      "Global Step: 321280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2510/3906, Global Timesteps: 321280\n",
      "\n",
      "--- Evaluation after Update 2520 ---\n",
      "Total Timesteps: 322560\n",
      "Mean Reward: 24.5 ± 4.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2520/3906\n",
      "Global Step: 322560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2520/3906, Global Timesteps: 322560\n",
      "\n",
      "--- Evaluation after Update 2530 ---\n",
      "Total Timesteps: 323840\n",
      "Mean Reward: 27.5 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2530/3906\n",
      "Global Step: 323840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2530/3906, Global Timesteps: 323840\n",
      "\n",
      "--- Evaluation after Update 2540 ---\n",
      "Total Timesteps: 325120\n",
      "Mean Reward: 22.7 ± 4.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2540/3906\n",
      "Global Step: 325120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2540/3906, Global Timesteps: 325120\n",
      "\n",
      "--- Evaluation after Update 2550 ---\n",
      "Total Timesteps: 326400\n",
      "Mean Reward: 22.9 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2550/3906\n",
      "Global Step: 326400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2550/3906, Global Timesteps: 326400\n",
      "\n",
      "--- Evaluation after Update 2560 ---\n",
      "Total Timesteps: 327680\n",
      "Mean Reward: 24.9 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2560/3906\n",
      "Global Step: 327680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2560/3906, Global Timesteps: 327680\n",
      "\n",
      "--- Evaluation after Update 2570 ---\n",
      "Total Timesteps: 328960\n",
      "Mean Reward: 22.4 ± 4.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2570/3906\n",
      "Global Step: 328960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2570/3906, Global Timesteps: 328960\n",
      "\n",
      "--- Evaluation after Update 2580 ---\n",
      "Total Timesteps: 330240\n",
      "Mean Reward: 22.1 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2580/3906\n",
      "Global Step: 330240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2580/3906, Global Timesteps: 330240\n",
      "\n",
      "--- Evaluation after Update 2590 ---\n",
      "Total Timesteps: 331520\n",
      "Mean Reward: 25.8 ± 6.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2590/3906\n",
      "Global Step: 331520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2590/3906, Global Timesteps: 331520\n",
      "\n",
      "--- Evaluation after Update 2600 ---\n",
      "Total Timesteps: 332800\n",
      "Mean Reward: 24.3 ± 6.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2600/3906\n",
      "Global Step: 332800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2600/3906, Global Timesteps: 332800\n",
      "\n",
      "--- Evaluation after Update 2610 ---\n",
      "Total Timesteps: 334080\n",
      "Mean Reward: 23.4 ± 6.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2610/3906\n",
      "Global Step: 334080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2610/3906, Global Timesteps: 334080\n",
      "\n",
      "--- Evaluation after Update 2620 ---\n",
      "Total Timesteps: 335360\n",
      "Mean Reward: 22.3 ± 7.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2620/3906\n",
      "Global Step: 335360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2620/3906, Global Timesteps: 335360\n",
      "\n",
      "--- Evaluation after Update 2630 ---\n",
      "Total Timesteps: 336640\n",
      "Mean Reward: 25.7 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2630/3906\n",
      "Global Step: 336640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2630/3906, Global Timesteps: 336640\n",
      "\n",
      "--- Evaluation after Update 2640 ---\n",
      "Total Timesteps: 337920\n",
      "Mean Reward: 23.7 ± 3.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2640/3906\n",
      "Global Step: 337920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2640/3906, Global Timesteps: 337920\n",
      "\n",
      "--- Evaluation after Update 2650 ---\n",
      "Total Timesteps: 339200\n",
      "Mean Reward: 26.7 ± 7.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2650/3906\n",
      "Global Step: 339200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2650/3906, Global Timesteps: 339200\n",
      "\n",
      "--- Evaluation after Update 2660 ---\n",
      "Total Timesteps: 340480\n",
      "Mean Reward: 24.7 ± 7.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2660/3906\n",
      "Global Step: 340480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2660/3906, Global Timesteps: 340480\n",
      "\n",
      "--- Evaluation after Update 2670 ---\n",
      "Total Timesteps: 341760\n",
      "Mean Reward: 23.3 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2670/3906\n",
      "Global Step: 341760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2670/3906, Global Timesteps: 341760\n",
      "\n",
      "--- Evaluation after Update 2680 ---\n",
      "Total Timesteps: 343040\n",
      "Mean Reward: 23.5 ± 6.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2680/3906\n",
      "Global Step: 343040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2680/3906, Global Timesteps: 343040\n",
      "\n",
      "--- Evaluation after Update 2690 ---\n",
      "Total Timesteps: 344320\n",
      "Mean Reward: 23.6 ± 3.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2690/3906\n",
      "Global Step: 344320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2690/3906, Global Timesteps: 344320\n",
      "\n",
      "--- Evaluation after Update 2700 ---\n",
      "Total Timesteps: 345600\n",
      "Mean Reward: 23.1 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2700/3906\n",
      "Global Step: 345600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2700/3906, Global Timesteps: 345600\n",
      "\n",
      "--- Evaluation after Update 2710 ---\n",
      "Total Timesteps: 346880\n",
      "Mean Reward: 25.2 ± 6.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2710/3906\n",
      "Global Step: 346880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2710/3906, Global Timesteps: 346880\n",
      "\n",
      "--- Evaluation after Update 2720 ---\n",
      "Total Timesteps: 348160\n",
      "Mean Reward: 23.4 ± 3.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2720/3906\n",
      "Global Step: 348160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2720/3906, Global Timesteps: 348160\n",
      "\n",
      "--- Evaluation after Update 2730 ---\n",
      "Total Timesteps: 349440\n",
      "Mean Reward: 20.5 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2730/3906\n",
      "Global Step: 349440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2730/3906, Global Timesteps: 349440\n",
      "\n",
      "--- Evaluation after Update 2740 ---\n",
      "Total Timesteps: 350720\n",
      "Mean Reward: 24.7 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2740/3906\n",
      "Global Step: 350720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2740/3906, Global Timesteps: 350720\n",
      "\n",
      "--- Evaluation after Update 2750 ---\n",
      "Total Timesteps: 352000\n",
      "Mean Reward: 22.1 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2750/3906\n",
      "Global Step: 352000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2750/3906, Global Timesteps: 352000\n",
      "\n",
      "--- Evaluation after Update 2760 ---\n",
      "Total Timesteps: 353280\n",
      "Mean Reward: 25.1 ± 4.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2760/3906\n",
      "Global Step: 353280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2760/3906, Global Timesteps: 353280\n",
      "\n",
      "--- Evaluation after Update 2770 ---\n",
      "Total Timesteps: 354560\n",
      "Mean Reward: 26.9 ± 7.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2770/3906\n",
      "Global Step: 354560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2770/3906, Global Timesteps: 354560\n",
      "\n",
      "--- Evaluation after Update 2780 ---\n",
      "Total Timesteps: 355840\n",
      "Mean Reward: 23.5 ± 5.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2780/3906\n",
      "Global Step: 355840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2780/3906, Global Timesteps: 355840\n",
      "\n",
      "--- Evaluation after Update 2790 ---\n",
      "Total Timesteps: 357120\n",
      "Mean Reward: 24.7 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2790/3906\n",
      "Global Step: 357120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2790/3906, Global Timesteps: 357120\n",
      "\n",
      "--- Evaluation after Update 2800 ---\n",
      "Total Timesteps: 358400\n",
      "Mean Reward: 25.4 ± 6.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2800/3906\n",
      "Global Step: 358400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2800/3906, Global Timesteps: 358400\n",
      "\n",
      "--- Evaluation after Update 2810 ---\n",
      "Total Timesteps: 359680\n",
      "Mean Reward: 25.3 ± 8.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2810/3906\n",
      "Global Step: 359680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2810/3906, Global Timesteps: 359680\n",
      "\n",
      "--- Evaluation after Update 2820 ---\n",
      "Total Timesteps: 360960\n",
      "Mean Reward: 20.3 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2820/3906\n",
      "Global Step: 360960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2820/3906, Global Timesteps: 360960\n",
      "\n",
      "--- Evaluation after Update 2830 ---\n",
      "Total Timesteps: 362240\n",
      "Mean Reward: 24.0 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2830/3906\n",
      "Global Step: 362240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2830/3906, Global Timesteps: 362240\n",
      "\n",
      "--- Evaluation after Update 2840 ---\n",
      "Total Timesteps: 363520\n",
      "Mean Reward: 23.6 ± 3.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2840/3906\n",
      "Global Step: 363520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2840/3906, Global Timesteps: 363520\n",
      "\n",
      "--- Evaluation after Update 2850 ---\n",
      "Total Timesteps: 364800\n",
      "Mean Reward: 26.3 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2850/3906\n",
      "Global Step: 364800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2850/3906, Global Timesteps: 364800\n",
      "\n",
      "--- Evaluation after Update 2860 ---\n",
      "Total Timesteps: 366080\n",
      "Mean Reward: 27.3 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2860/3906\n",
      "Global Step: 366080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2860/3906, Global Timesteps: 366080\n",
      "\n",
      "--- Evaluation after Update 2870 ---\n",
      "Total Timesteps: 367360\n",
      "Mean Reward: 25.1 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2870/3906\n",
      "Global Step: 367360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2870/3906, Global Timesteps: 367360\n",
      "\n",
      "--- Evaluation after Update 2880 ---\n",
      "Total Timesteps: 368640\n",
      "Mean Reward: 24.0 ± 2.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2880/3906\n",
      "Global Step: 368640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2880/3906, Global Timesteps: 368640\n",
      "\n",
      "--- Evaluation after Update 2890 ---\n",
      "Total Timesteps: 369920\n",
      "Mean Reward: 19.8 ± 3.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2890/3906\n",
      "Global Step: 369920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2890/3906, Global Timesteps: 369920\n",
      "\n",
      "--- Evaluation after Update 2900 ---\n",
      "Total Timesteps: 371200\n",
      "Mean Reward: 24.5 ± 4.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2900/3906\n",
      "Global Step: 371200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2900/3906, Global Timesteps: 371200\n",
      "\n",
      "--- Evaluation after Update 2910 ---\n",
      "Total Timesteps: 372480\n",
      "Mean Reward: 24.1 ± 6.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2910/3906\n",
      "Global Step: 372480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2910/3906, Global Timesteps: 372480\n",
      "\n",
      "--- Evaluation after Update 2920 ---\n",
      "Total Timesteps: 373760\n",
      "Mean Reward: 23.7 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2920/3906\n",
      "Global Step: 373760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2920/3906, Global Timesteps: 373760\n",
      "\n",
      "--- Evaluation after Update 2930 ---\n",
      "Total Timesteps: 375040\n",
      "Mean Reward: 24.0 ± 3.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2930/3906\n",
      "Global Step: 375040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2930/3906, Global Timesteps: 375040\n",
      "\n",
      "--- Evaluation after Update 2940 ---\n",
      "Total Timesteps: 376320\n",
      "Mean Reward: 21.8 ± 6.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2940/3906\n",
      "Global Step: 376320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2940/3906, Global Timesteps: 376320\n",
      "\n",
      "--- Evaluation after Update 2950 ---\n",
      "Total Timesteps: 377600\n",
      "Mean Reward: 21.8 ± 3.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2950/3906\n",
      "Global Step: 377600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2950/3906, Global Timesteps: 377600\n",
      "\n",
      "--- Evaluation after Update 2960 ---\n",
      "Total Timesteps: 378880\n",
      "Mean Reward: 24.2 ± 4.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2960/3906\n",
      "Global Step: 378880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2960/3906, Global Timesteps: 378880\n",
      "\n",
      "--- Evaluation after Update 2970 ---\n",
      "Total Timesteps: 380160\n",
      "Mean Reward: 23.2 ± 4.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2970/3906\n",
      "Global Step: 380160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2970/3906, Global Timesteps: 380160\n",
      "\n",
      "--- Evaluation after Update 2980 ---\n",
      "Total Timesteps: 381440\n",
      "Mean Reward: 25.1 ± 8.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2980/3906\n",
      "Global Step: 381440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2980/3906, Global Timesteps: 381440\n",
      "\n",
      "--- Evaluation after Update 2990 ---\n",
      "Total Timesteps: 382720\n",
      "Mean Reward: 24.0 ± 3.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 2990/3906\n",
      "Global Step: 382720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 2990/3906, Global Timesteps: 382720\n",
      "\n",
      "--- Evaluation after Update 3000 ---\n",
      "Total Timesteps: 384000\n",
      "Mean Reward: 26.1 ± 5.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3000/3906\n",
      "Global Step: 384000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3000/3906, Global Timesteps: 384000\n",
      "\n",
      "--- Evaluation after Update 3010 ---\n",
      "Total Timesteps: 385280\n",
      "Mean Reward: 23.4 ± 5.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3010/3906\n",
      "Global Step: 385280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3010/3906, Global Timesteps: 385280\n",
      "\n",
      "--- Evaluation after Update 3020 ---\n",
      "Total Timesteps: 386560\n",
      "Mean Reward: 23.4 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3020/3906\n",
      "Global Step: 386560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3020/3906, Global Timesteps: 386560\n",
      "\n",
      "--- Evaluation after Update 3030 ---\n",
      "Total Timesteps: 387840\n",
      "Mean Reward: 25.4 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3030/3906\n",
      "Global Step: 387840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3030/3906, Global Timesteps: 387840\n",
      "\n",
      "--- Evaluation after Update 3040 ---\n",
      "Total Timesteps: 389120\n",
      "Mean Reward: 20.9 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3040/3906\n",
      "Global Step: 389120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3040/3906, Global Timesteps: 389120\n",
      "\n",
      "--- Evaluation after Update 3050 ---\n",
      "Total Timesteps: 390400\n",
      "Mean Reward: 23.2 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3050/3906\n",
      "Global Step: 390400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3050/3906, Global Timesteps: 390400\n",
      "\n",
      "--- Evaluation after Update 3060 ---\n",
      "Total Timesteps: 391680\n",
      "Mean Reward: 25.1 ± 4.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3060/3906\n",
      "Global Step: 391680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3060/3906, Global Timesteps: 391680\n",
      "\n",
      "--- Evaluation after Update 3070 ---\n",
      "Total Timesteps: 392960\n",
      "Mean Reward: 25.1 ± 8.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3070/3906\n",
      "Global Step: 392960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3070/3906, Global Timesteps: 392960\n",
      "\n",
      "--- Evaluation after Update 3080 ---\n",
      "Total Timesteps: 394240\n",
      "Mean Reward: 20.5 ± 6.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3080/3906\n",
      "Global Step: 394240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3080/3906, Global Timesteps: 394240\n",
      "\n",
      "--- Evaluation after Update 3090 ---\n",
      "Total Timesteps: 395520\n",
      "Mean Reward: 23.1 ± 4.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3090/3906\n",
      "Global Step: 395520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3090/3906, Global Timesteps: 395520\n",
      "\n",
      "--- Evaluation after Update 3100 ---\n",
      "Total Timesteps: 396800\n",
      "Mean Reward: 23.2 ± 3.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3100/3906\n",
      "Global Step: 396800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3100/3906, Global Timesteps: 396800\n",
      "\n",
      "--- Evaluation after Update 3110 ---\n",
      "Total Timesteps: 398080\n",
      "Mean Reward: 23.9 ± 4.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3110/3906\n",
      "Global Step: 398080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3110/3906, Global Timesteps: 398080\n",
      "\n",
      "--- Evaluation after Update 3120 ---\n",
      "Total Timesteps: 399360\n",
      "Mean Reward: 25.3 ± 5.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3120/3906\n",
      "Global Step: 399360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3120/3906, Global Timesteps: 399360\n",
      "\n",
      "--- Evaluation after Update 3130 ---\n",
      "Total Timesteps: 400640\n",
      "Mean Reward: 23.7 ± 7.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3130/3906\n",
      "Global Step: 400640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3130/3906, Global Timesteps: 400640\n",
      "\n",
      "--- Evaluation after Update 3140 ---\n",
      "Total Timesteps: 401920\n",
      "Mean Reward: 23.4 ± 3.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3140/3906\n",
      "Global Step: 401920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3140/3906, Global Timesteps: 401920\n",
      "\n",
      "--- Evaluation after Update 3150 ---\n",
      "Total Timesteps: 403200\n",
      "Mean Reward: 21.6 ± 7.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3150/3906\n",
      "Global Step: 403200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3150/3906, Global Timesteps: 403200\n",
      "\n",
      "--- Evaluation after Update 3160 ---\n",
      "Total Timesteps: 404480\n",
      "Mean Reward: 24.6 ± 2.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3160/3906\n",
      "Global Step: 404480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3160/3906, Global Timesteps: 404480\n",
      "\n",
      "--- Evaluation after Update 3170 ---\n",
      "Total Timesteps: 405760\n",
      "Mean Reward: 25.0 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3170/3906\n",
      "Global Step: 405760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3170/3906, Global Timesteps: 405760\n",
      "\n",
      "--- Evaluation after Update 3180 ---\n",
      "Total Timesteps: 407040\n",
      "Mean Reward: 21.8 ± 4.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3180/3906\n",
      "Global Step: 407040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3180/3906, Global Timesteps: 407040\n",
      "\n",
      "--- Evaluation after Update 3190 ---\n",
      "Total Timesteps: 408320\n",
      "Mean Reward: 24.3 ± 5.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3190/3906\n",
      "Global Step: 408320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3190/3906, Global Timesteps: 408320\n",
      "\n",
      "--- Evaluation after Update 3200 ---\n",
      "Total Timesteps: 409600\n",
      "Mean Reward: 22.5 ± 5.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3200/3906\n",
      "Global Step: 409600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3200/3906, Global Timesteps: 409600\n",
      "\n",
      "--- Evaluation after Update 3210 ---\n",
      "Total Timesteps: 410880\n",
      "Mean Reward: 21.2 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3210/3906\n",
      "Global Step: 410880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3210/3906, Global Timesteps: 410880\n",
      "\n",
      "--- Evaluation after Update 3220 ---\n",
      "Total Timesteps: 412160\n",
      "Mean Reward: 26.3 ± 3.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3220/3906\n",
      "Global Step: 412160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3220/3906, Global Timesteps: 412160\n",
      "\n",
      "--- Evaluation after Update 3230 ---\n",
      "Total Timesteps: 413440\n",
      "Mean Reward: 26.2 ± 3.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3230/3906\n",
      "Global Step: 413440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3230/3906, Global Timesteps: 413440\n",
      "\n",
      "--- Evaluation after Update 3240 ---\n",
      "Total Timesteps: 414720\n",
      "Mean Reward: 21.6 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3240/3906\n",
      "Global Step: 414720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3240/3906, Global Timesteps: 414720\n",
      "\n",
      "--- Evaluation after Update 3250 ---\n",
      "Total Timesteps: 416000\n",
      "Mean Reward: 23.0 ± 4.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3250/3906\n",
      "Global Step: 416000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3250/3906, Global Timesteps: 416000\n",
      "\n",
      "--- Evaluation after Update 3260 ---\n",
      "Total Timesteps: 417280\n",
      "Mean Reward: 22.3 ± 4.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3260/3906\n",
      "Global Step: 417280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3260/3906, Global Timesteps: 417280\n",
      "\n",
      "--- Evaluation after Update 3270 ---\n",
      "Total Timesteps: 418560\n",
      "Mean Reward: 25.5 ± 7.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3270/3906\n",
      "Global Step: 418560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3270/3906, Global Timesteps: 418560\n",
      "\n",
      "--- Evaluation after Update 3280 ---\n",
      "Total Timesteps: 419840\n",
      "Mean Reward: 25.6 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3280/3906\n",
      "Global Step: 419840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3280/3906, Global Timesteps: 419840\n",
      "\n",
      "--- Evaluation after Update 3290 ---\n",
      "Total Timesteps: 421120\n",
      "Mean Reward: 24.4 ± 7.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3290/3906\n",
      "Global Step: 421120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3290/3906, Global Timesteps: 421120\n",
      "\n",
      "--- Evaluation after Update 3300 ---\n",
      "Total Timesteps: 422400\n",
      "Mean Reward: 24.8 ± 4.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3300/3906\n",
      "Global Step: 422400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3300/3906, Global Timesteps: 422400\n",
      "\n",
      "--- Evaluation after Update 3310 ---\n",
      "Total Timesteps: 423680\n",
      "Mean Reward: 23.6 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3310/3906\n",
      "Global Step: 423680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3310/3906, Global Timesteps: 423680\n",
      "\n",
      "--- Evaluation after Update 3320 ---\n",
      "Total Timesteps: 424960\n",
      "Mean Reward: 24.1 ± 7.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3320/3906\n",
      "Global Step: 424960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3320/3906, Global Timesteps: 424960\n",
      "\n",
      "--- Evaluation after Update 3330 ---\n",
      "Total Timesteps: 426240\n",
      "Mean Reward: 23.6 ± 6.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3330/3906\n",
      "Global Step: 426240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3330/3906, Global Timesteps: 426240\n",
      "\n",
      "--- Evaluation after Update 3340 ---\n",
      "Total Timesteps: 427520\n",
      "Mean Reward: 26.1 ± 5.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3340/3906\n",
      "Global Step: 427520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3340/3906, Global Timesteps: 427520\n",
      "\n",
      "--- Evaluation after Update 3350 ---\n",
      "Total Timesteps: 428800\n",
      "Mean Reward: 24.5 ± 8.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3350/3906\n",
      "Global Step: 428800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3350/3906, Global Timesteps: 428800\n",
      "\n",
      "--- Evaluation after Update 3360 ---\n",
      "Total Timesteps: 430080\n",
      "Mean Reward: 25.5 ± 4.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3360/3906\n",
      "Global Step: 430080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3360/3906, Global Timesteps: 430080\n",
      "\n",
      "--- Evaluation after Update 3370 ---\n",
      "Total Timesteps: 431360\n",
      "Mean Reward: 24.9 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3370/3906\n",
      "Global Step: 431360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3370/3906, Global Timesteps: 431360\n",
      "\n",
      "--- Evaluation after Update 3380 ---\n",
      "Total Timesteps: 432640\n",
      "Mean Reward: 21.5 ± 4.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3380/3906\n",
      "Global Step: 432640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3380/3906, Global Timesteps: 432640\n",
      "\n",
      "--- Evaluation after Update 3390 ---\n",
      "Total Timesteps: 433920\n",
      "Mean Reward: 20.2 ± 3.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3390/3906\n",
      "Global Step: 433920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3390/3906, Global Timesteps: 433920\n",
      "\n",
      "--- Evaluation after Update 3400 ---\n",
      "Total Timesteps: 435200\n",
      "Mean Reward: 23.8 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3400/3906\n",
      "Global Step: 435200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3400/3906, Global Timesteps: 435200\n",
      "\n",
      "--- Evaluation after Update 3410 ---\n",
      "Total Timesteps: 436480\n",
      "Mean Reward: 19.6 ± 6.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3410/3906\n",
      "Global Step: 436480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3410/3906, Global Timesteps: 436480\n",
      "\n",
      "--- Evaluation after Update 3420 ---\n",
      "Total Timesteps: 437760\n",
      "Mean Reward: 21.3 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3420/3906\n",
      "Global Step: 437760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3420/3906, Global Timesteps: 437760\n",
      "\n",
      "--- Evaluation after Update 3430 ---\n",
      "Total Timesteps: 439040\n",
      "Mean Reward: 24.0 ± 2.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3430/3906\n",
      "Global Step: 439040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3430/3906, Global Timesteps: 439040\n",
      "\n",
      "--- Evaluation after Update 3440 ---\n",
      "Total Timesteps: 440320\n",
      "Mean Reward: 25.1 ± 3.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3440/3906\n",
      "Global Step: 440320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3440/3906, Global Timesteps: 440320\n",
      "\n",
      "--- Evaluation after Update 3450 ---\n",
      "Total Timesteps: 441600\n",
      "Mean Reward: 24.6 ± 3.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3450/3906\n",
      "Global Step: 441600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3450/3906, Global Timesteps: 441600\n",
      "\n",
      "--- Evaluation after Update 3460 ---\n",
      "Total Timesteps: 442880\n",
      "Mean Reward: 24.2 ± 7.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3460/3906\n",
      "Global Step: 442880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3460/3906, Global Timesteps: 442880\n",
      "\n",
      "--- Evaluation after Update 3470 ---\n",
      "Total Timesteps: 444160\n",
      "Mean Reward: 24.3 ± 4.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3470/3906\n",
      "Global Step: 444160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3470/3906, Global Timesteps: 444160\n",
      "\n",
      "--- Evaluation after Update 3480 ---\n",
      "Total Timesteps: 445440\n",
      "Mean Reward: 20.7 ± 6.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3480/3906\n",
      "Global Step: 445440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3480/3906, Global Timesteps: 445440\n",
      "\n",
      "--- Evaluation after Update 3490 ---\n",
      "Total Timesteps: 446720\n",
      "Mean Reward: 22.9 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3490/3906\n",
      "Global Step: 446720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3490/3906, Global Timesteps: 446720\n",
      "\n",
      "--- Evaluation after Update 3500 ---\n",
      "Total Timesteps: 448000\n",
      "Mean Reward: 20.3 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3500/3906\n",
      "Global Step: 448000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3500/3906, Global Timesteps: 448000\n",
      "\n",
      "--- Evaluation after Update 3510 ---\n",
      "Total Timesteps: 449280\n",
      "Mean Reward: 20.8 ± 3.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3510/3906\n",
      "Global Step: 449280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3510/3906, Global Timesteps: 449280\n",
      "\n",
      "--- Evaluation after Update 3520 ---\n",
      "Total Timesteps: 450560\n",
      "Mean Reward: 22.3 ± 5.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3520/3906\n",
      "Global Step: 450560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3520/3906, Global Timesteps: 450560\n",
      "\n",
      "--- Evaluation after Update 3530 ---\n",
      "Total Timesteps: 451840\n",
      "Mean Reward: 25.3 ± 6.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3530/3906\n",
      "Global Step: 451840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3530/3906, Global Timesteps: 451840\n",
      "\n",
      "--- Evaluation after Update 3540 ---\n",
      "Total Timesteps: 453120\n",
      "Mean Reward: 23.2 ± 6.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3540/3906\n",
      "Global Step: 453120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3540/3906, Global Timesteps: 453120\n",
      "\n",
      "--- Evaluation after Update 3550 ---\n",
      "Total Timesteps: 454400\n",
      "Mean Reward: 21.8 ± 6.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3550/3906\n",
      "Global Step: 454400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3550/3906, Global Timesteps: 454400\n",
      "\n",
      "--- Evaluation after Update 3560 ---\n",
      "Total Timesteps: 455680\n",
      "Mean Reward: 22.9 ± 4.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3560/3906\n",
      "Global Step: 455680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3560/3906, Global Timesteps: 455680\n",
      "\n",
      "--- Evaluation after Update 3570 ---\n",
      "Total Timesteps: 456960\n",
      "Mean Reward: 23.5 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3570/3906\n",
      "Global Step: 456960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3570/3906, Global Timesteps: 456960\n",
      "\n",
      "--- Evaluation after Update 3580 ---\n",
      "Total Timesteps: 458240\n",
      "Mean Reward: 24.4 ± 6.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3580/3906\n",
      "Global Step: 458240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3580/3906, Global Timesteps: 458240\n",
      "\n",
      "--- Evaluation after Update 3590 ---\n",
      "Total Timesteps: 459520\n",
      "Mean Reward: 22.5 ± 5.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3590/3906\n",
      "Global Step: 459520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3590/3906, Global Timesteps: 459520\n",
      "\n",
      "--- Evaluation after Update 3600 ---\n",
      "Total Timesteps: 460800\n",
      "Mean Reward: 21.8 ± 4.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3600/3906\n",
      "Global Step: 460800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3600/3906, Global Timesteps: 460800\n",
      "\n",
      "--- Evaluation after Update 3610 ---\n",
      "Total Timesteps: 462080\n",
      "Mean Reward: 23.1 ± 3.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3610/3906\n",
      "Global Step: 462080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3610/3906, Global Timesteps: 462080\n",
      "\n",
      "--- Evaluation after Update 3620 ---\n",
      "Total Timesteps: 463360\n",
      "Mean Reward: 24.8 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3620/3906\n",
      "Global Step: 463360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3620/3906, Global Timesteps: 463360\n",
      "\n",
      "--- Evaluation after Update 3630 ---\n",
      "Total Timesteps: 464640\n",
      "Mean Reward: 22.6 ± 4.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3630/3906\n",
      "Global Step: 464640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3630/3906, Global Timesteps: 464640\n",
      "\n",
      "--- Evaluation after Update 3640 ---\n",
      "Total Timesteps: 465920\n",
      "Mean Reward: 22.2 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3640/3906\n",
      "Global Step: 465920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3640/3906, Global Timesteps: 465920\n",
      "\n",
      "--- Evaluation after Update 3650 ---\n",
      "Total Timesteps: 467200\n",
      "Mean Reward: 21.6 ± 4.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3650/3906\n",
      "Global Step: 467200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3650/3906, Global Timesteps: 467200\n",
      "\n",
      "--- Evaluation after Update 3660 ---\n",
      "Total Timesteps: 468480\n",
      "Mean Reward: 22.7 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3660/3906\n",
      "Global Step: 468480\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3660/3906, Global Timesteps: 468480\n",
      "\n",
      "--- Evaluation after Update 3670 ---\n",
      "Total Timesteps: 469760\n",
      "Mean Reward: 22.9 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3670/3906\n",
      "Global Step: 469760\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3670/3906, Global Timesteps: 469760\n",
      "\n",
      "--- Evaluation after Update 3680 ---\n",
      "Total Timesteps: 471040\n",
      "Mean Reward: 25.6 ± 4.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3680/3906\n",
      "Global Step: 471040\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3680/3906, Global Timesteps: 471040\n",
      "\n",
      "--- Evaluation after Update 3690 ---\n",
      "Total Timesteps: 472320\n",
      "Mean Reward: 25.5 ± 5.9\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3690/3906\n",
      "Global Step: 472320\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3690/3906, Global Timesteps: 472320\n",
      "\n",
      "--- Evaluation after Update 3700 ---\n",
      "Total Timesteps: 473600\n",
      "Mean Reward: 24.9 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3700/3906\n",
      "Global Step: 473600\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3700/3906, Global Timesteps: 473600\n",
      "\n",
      "--- Evaluation after Update 3710 ---\n",
      "Total Timesteps: 474880\n",
      "Mean Reward: 24.7 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3710/3906\n",
      "Global Step: 474880\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3710/3906, Global Timesteps: 474880\n",
      "\n",
      "--- Evaluation after Update 3720 ---\n",
      "Total Timesteps: 476160\n",
      "Mean Reward: 22.5 ± 4.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3720/3906\n",
      "Global Step: 476160\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3720/3906, Global Timesteps: 476160\n",
      "\n",
      "--- Evaluation after Update 3730 ---\n",
      "Total Timesteps: 477440\n",
      "Mean Reward: 25.0 ± 7.6\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3730/3906\n",
      "Global Step: 477440\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3730/3906, Global Timesteps: 477440\n",
      "\n",
      "--- Evaluation after Update 3740 ---\n",
      "Total Timesteps: 478720\n",
      "Mean Reward: 23.4 ± 3.7\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3740/3906\n",
      "Global Step: 478720\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3740/3906, Global Timesteps: 478720\n",
      "\n",
      "--- Evaluation after Update 3750 ---\n",
      "Total Timesteps: 480000\n",
      "Mean Reward: 21.1 ± 7.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3750/3906\n",
      "Global Step: 480000\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3750/3906, Global Timesteps: 480000\n",
      "\n",
      "--- Evaluation after Update 3760 ---\n",
      "Total Timesteps: 481280\n",
      "Mean Reward: 22.7 ± 4.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3760/3906\n",
      "Global Step: 481280\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3760/3906, Global Timesteps: 481280\n",
      "\n",
      "--- Evaluation after Update 3770 ---\n",
      "Total Timesteps: 482560\n",
      "Mean Reward: 22.8 ± 8.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3770/3906\n",
      "Global Step: 482560\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3770/3906, Global Timesteps: 482560\n",
      "\n",
      "--- Evaluation after Update 3780 ---\n",
      "Total Timesteps: 483840\n",
      "Mean Reward: 23.0 ± 4.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3780/3906\n",
      "Global Step: 483840\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3780/3906, Global Timesteps: 483840\n",
      "\n",
      "--- Evaluation after Update 3790 ---\n",
      "Total Timesteps: 485120\n",
      "Mean Reward: 22.7 ± 4.3\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3790/3906\n",
      "Global Step: 485120\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3790/3906, Global Timesteps: 485120\n",
      "\n",
      "--- Evaluation after Update 3800 ---\n",
      "Total Timesteps: 486400\n",
      "Mean Reward: 23.2 ± 3.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3800/3906\n",
      "Global Step: 486400\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3800/3906, Global Timesteps: 486400\n",
      "\n",
      "--- Evaluation after Update 3810 ---\n",
      "Total Timesteps: 487680\n",
      "Mean Reward: 22.1 ± 5.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3810/3906\n",
      "Global Step: 487680\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3810/3906, Global Timesteps: 487680\n",
      "\n",
      "--- Evaluation after Update 3820 ---\n",
      "Total Timesteps: 488960\n",
      "Mean Reward: 24.0 ± 4.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3820/3906\n",
      "Global Step: 488960\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3820/3906, Global Timesteps: 488960\n",
      "\n",
      "--- Evaluation after Update 3830 ---\n",
      "Total Timesteps: 490240\n",
      "Mean Reward: 20.4 ± 3.0\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3830/3906\n",
      "Global Step: 490240\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3830/3906, Global Timesteps: 490240\n",
      "\n",
      "--- Evaluation after Update 3840 ---\n",
      "Total Timesteps: 491520\n",
      "Mean Reward: 22.8 ± 5.1\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3840/3906\n",
      "Global Step: 491520\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3840/3906, Global Timesteps: 491520\n",
      "\n",
      "--- Evaluation after Update 3850 ---\n",
      "Total Timesteps: 492800\n",
      "Mean Reward: 22.0 ± 5.2\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3850/3906\n",
      "Global Step: 492800\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3850/3906, Global Timesteps: 492800\n",
      "\n",
      "--- Evaluation after Update 3860 ---\n",
      "Total Timesteps: 494080\n",
      "Mean Reward: 26.8 ± 7.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3860/3906\n",
      "Global Step: 494080\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3860/3906, Global Timesteps: 494080\n",
      "\n",
      "--- Evaluation after Update 3870 ---\n",
      "Total Timesteps: 495360\n",
      "Mean Reward: 20.1 ± 5.4\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3870/3906\n",
      "Global Step: 495360\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3870/3906, Global Timesteps: 495360\n",
      "\n",
      "--- Evaluation after Update 3880 ---\n",
      "Total Timesteps: 496640\n",
      "Mean Reward: 25.2 ± 5.8\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3880/3906\n",
      "Global Step: 496640\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3880/3906, Global Timesteps: 496640\n",
      "\n",
      "--- Evaluation after Update 3890 ---\n",
      "Total Timesteps: 497920\n",
      "Mean Reward: 23.8 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3890/3906\n",
      "Global Step: 497920\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3890/3906, Global Timesteps: 497920\n",
      "\n",
      "--- Evaluation after Update 3900 ---\n",
      "Total Timesteps: 499200\n",
      "Mean Reward: 23.6 ± 4.5\n",
      "Current Training Episode Reward: N/A\n",
      "\n",
      "Update 3900/3906\n",
      "Global Step: 499200\n",
      "Approx KL Divergence: 0.000\n",
      "Clip Fraction: 0.000\n",
      "Value Loss: 0.000\n",
      "Update 3900/3906, Global Timesteps: 499200\n",
      "\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "global_step = 0\n",
    "num_updates = TOTAL_TIMESTEPS // (NUM_STEPS_PER_ROLLOUT * NUM_ENVS)\n",
    "\n",
    "# Initial observation\n",
    "# IMPORTANT: env.reset() returns a tuple (observation, info). We only need observation.\n",
    "# Also, observation needs to be converted to a tensor and have a batch dimension.\n",
    "current_obs_tuple = env.reset(seed=42)\n",
    "current_obs = torch.Tensor(current_obs_tuple[0]).to(DEVICE).unsqueeze(0) # Add batch dim for single env\n",
    "current_done = torch.zeros(NUM_ENVS).to(DEVICE) # For single env, NUM_ENVS=1\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for update in range(1, num_updates + 1):\n",
    "    # --- Data Collection (Rollout Phase) ---\n",
    "    for step in range(0, NUM_STEPS_PER_ROLLOUT):\n",
    "        global_step += 1 * NUM_ENVS\n",
    "        obs_storage[step] = current_obs # current_obs already has batch dim (1, H, W, C)\n",
    "\n",
    "        with torch.no_grad(): # Don't need gradients for action selection and value estimation here\n",
    "            action, logprob, _ = actor.get_action_and_value(current_obs) # current_obs is (1, H, W, C)\n",
    "            value = critic.get_value(current_obs)\n",
    "\n",
    "        actions_storage[step] = action.squeeze() # Squeeze if action is (1,1) to (1)\n",
    "        logprobs_storage[step] = logprob.squeeze()\n",
    "        values_storage[step] = value.squeeze()\n",
    "\n",
    "        # Execute action in the environment\n",
    "        # env.step returns (observation, reward, terminated, truncated, info)\n",
    "        next_obs_tuple, reward, terminated, truncated, info = env.step(action.cpu().numpy().item()) # Send one action\n",
    "        done = terminated or truncated\n",
    "\n",
    "        rewards_storage[step] = torch.tensor(reward).to(DEVICE).view(-1) # Ensure reward is a tensor\n",
    "        # current_obs needs to be (1, H, W, C)\n",
    "        current_obs = torch.Tensor(next_obs_tuple).to(DEVICE).unsqueeze(0)\n",
    "        current_done = torch.tensor(done).to(DEVICE).view(-1) # Ensure done is a tensor\n",
    "        dones_storage[step] = current_done\n",
    "\n",
    "        if 'episode' in info: # Gymnasium environments often provide episode stats in info\n",
    "            print(f\"Global Step: {global_step}, Episode Reward: {info['episode']['r']}\")\n",
    "\n",
    "        if env.render_mode == \"human\":\n",
    "            env.render()\n",
    "            time.sleep(0.01) # Adjust sleep time\n",
    "\n",
    "    # --- Learning Phase ---\n",
    "    with torch.no_grad():\n",
    "        # Calculate advantages using GAE\n",
    "        # Get value of the last state in the rollout\n",
    "        next_value = critic.get_value(current_obs).reshape(1, -1) # current_obs is (1,H,W,C)\n",
    "        advantages = torch.zeros_like(rewards_storage).to(DEVICE)\n",
    "        lastgaelam = 0\n",
    "        for t in reversed(range(NUM_STEPS_PER_ROLLOUT)):\n",
    "            if t == NUM_STEPS_PER_ROLLOUT - 1:\n",
    "                nextnonterminal = 1.0 - current_done.float() # current_done is for the state *after* last step\n",
    "                nextvalues = next_value\n",
    "            else:\n",
    "                nextnonterminal = 1.0 - dones_storage[t + 1]\n",
    "                nextvalues = values_storage[t + 1]\n",
    "            delta = rewards_storage[t] + GAMMA * nextvalues * nextnonterminal - values_storage[t]\n",
    "            advantages[t] = lastgaelam = delta + GAMMA * GAE_LAMBDA * nextnonterminal * lastgaelam\n",
    "        returns = advantages + values_storage # Q-values estimates\n",
    "\n",
    "    # Flatten the batch for training\n",
    "    # obs_storage is (NUM_STEPS, NUM_ENVS, H, W, C) -> (NUM_STEPS*NUM_ENVS, H, W, C)\n",
    "    b_obs = obs_storage.reshape((-1,) + observation_shape)\n",
    "    b_logprobs = logprobs_storage.reshape(-1)\n",
    "    b_actions = actions_storage.reshape((-1,) + env.action_space.shape) # If action space is not scalar\n",
    "    b_advantages = advantages.reshape(-1)\n",
    "    b_returns = returns.reshape(-1)\n",
    "    b_values = values_storage.reshape(-1)\n",
    "\n",
    "    # Optimize policy and value networks\n",
    "    b_inds = np.arange(NUM_STEPS_PER_ROLLOUT * NUM_ENVS)\n",
    "    clipfracs = []\n",
    "    for epoch in range(NUM_EPOCHS_PER_UPDATE):\n",
    "        np.random.shuffle(b_inds)\n",
    "        for start in range(0, NUM_STEPS_PER_ROLLOUT * NUM_ENVS, NUM_STEPS_PER_ROLLOUT * NUM_ENVS // NUM_MINIBATCHES):\n",
    "            end = start + NUM_STEPS_PER_ROLLOUT * NUM_ENVS // NUM_MINIBATCHES\n",
    "            mb_inds = b_inds[start:end]\n",
    "\n",
    "            # Get new logprobs, entropy, and value for the minibatch observations\n",
    "            _, newlogprob, entropy = actor.get_action_and_value(b_obs[mb_inds], b_actions.long()[mb_inds])\n",
    "            newvalue = critic.get_value(b_obs[mb_inds]).view(-1)\n",
    "\n",
    "            logratio = newlogprob - b_logprobs[mb_inds]\n",
    "            ratio = logratio.exp()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                old_approx_kl = (-logratio).mean()\n",
    "                approx_kl = ((ratio - 1) - logratio).mean()\n",
    "                clipfracs += [((ratio - 1.0).abs() > CLIP_EPS).float().mean().item()]\n",
    "\n",
    "            mb_advantages = b_advantages[mb_inds]\n",
    "            # Normalize advantages (optional but often helpful)\n",
    "            mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
    "\n",
    "            # Policy loss\n",
    "            pg_loss1 = -mb_advantages * ratio\n",
    "            pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - CLIP_EPS, 1 + CLIP_EPS)\n",
    "            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "            # Value loss\n",
    "            v_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2\n",
    "            v_clipped = b_values[mb_inds] + torch.clamp(\n",
    "                newvalue - b_values[mb_inds],\n",
    "                -CLIP_EPS,\n",
    "                CLIP_EPS,\n",
    "            )\n",
    "            v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n",
    "            v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n",
    "            v_loss = 0.5 * v_loss_max.mean() # Can also use 0.5 * ((newvalue - b_returns[mb_inds])**2).mean()\n",
    "\n",
    "            entropy_loss = entropy.mean()\n",
    "            loss = pg_loss - ENTROPY_COEF * entropy_loss + v_loss * VALUE_LOSS_COEF\n",
    "\n",
    "            actor_optimizer.zero_grad()\n",
    "            \n",
    "            # Actor optimizer step\n",
    "            actor_optimizer.zero_grad()\n",
    "            actor_loss = pg_loss - ENTROPY_COEF * entropy_loss\n",
    "            actor_loss.backward(retain_graph=True) # Retain graph if critic loss depends on actor output somehow, or separate\n",
    "            nn.utils.clip_grad_norm_(actor.parameters(), MAX_GRAD_NORM)\n",
    "            actor_optimizer.step()\n",
    "\n",
    "            # Critic optimizer step\n",
    "            critic_optimizer.zero_grad()\n",
    "            # Value loss was: v_loss = 0.5 * ((newvalue - b_returns[mb_inds])**2).mean()\n",
    "            critic_true_loss = 0.5 * ((newvalue - b_returns[mb_inds])**2).mean() # Recalculate critic loss from its output\n",
    "            critic_true_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(critic.parameters(), MAX_GRAD_NORM)\n",
    "            critic_optimizer.step()\n",
    "\n",
    "\n",
    "        if TARGET_KL is not None and approx_kl > TARGET_KL:\n",
    "            print(f\"Approx KL {approx_kl.item()} exceeded target {TARGET_KL}. Stopping epoch early.\")\n",
    "            break\n",
    "    # End of learning phase for one update\n",
    "\n",
    "    # --- Evaluation & Metrics ---\n",
    "    if update % eval_freq == 0 or update == 1:\n",
    "        mean_reward, std_reward = evaluate(actor)\n",
    "        eval_results.append((global_step, mean_reward, std_reward))\n",
    "        \n",
    "        print(f\"\\n--- Evaluation after Update {update} ---\")\n",
    "        print(f\"Total Timesteps: {global_step}\")\n",
    "        print(f\"Mean Reward: {mean_reward:.1f} ± {std_reward:.1f}\")\n",
    "        print(f\"Current Training Episode Reward: {info['episode']['r'] if 'episode' in info else 'N/A'}\")\n",
    "        \n",
    "    # --- Periodic Logging ---\n",
    "    if (update % 10 == 0) or (update == 1):\n",
    "        print(f\"\\nUpdate {update}/{num_updates}\")\n",
    "        print(f\"Global Step: {global_step}\")\n",
    "        print(f\"Approx KL Divergence: {approx_kl.item():.3f}\")\n",
    "        print(f\"Clip Fraction: {np.mean(clipfracs):.3f}\")\n",
    "        print(f\"Value Loss: {v_loss.item():.3f}\")\n",
    "\n",
    "    # Print some stats\n",
    "    if (update % 10 == 0) or (update == 1): # Print every 10 updates\n",
    "        print(f\"Update {update}/{num_updates}, Global Timesteps: {global_step}\")\n",
    "        # Add more logging here: average reward, value loss, policy loss, entropy\n",
    "\n",
    "print(\"\\nTraining completed.\")\n",
    "env.close()\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30964d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "steps, means, stds = zip(*eval_results)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.errorbar(steps, means, yerr=stds, fmt='-o', capsize=5)\n",
    "plt.title(\"Evaluation Performance During Training\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Mean Reward ± SD\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"training_metrics.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7552da00",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbaa1d1",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "564d0568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "steps, means, stds = zip(*eval_results)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(steps, means, 'b-', label='Mean Reward')\n",
    "plt.fill_between(steps, \n",
    "                 [m - s for m, s in zip(means, stds)], \n",
    "                 [m + s for m, s in zip(means, stds)], \n",
    "                 alpha=0.2)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('Evaluation Reward')\n",
    "plt.title('PPO Learning Curve')\n",
    "plt.grid(True)\n",
    "plt.savefig('learning_curve.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2008375",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## New Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88110a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Eval after update 1: mean reward 0.00 ± 0.00\n",
      "Eval after update 10: mean reward 0.00 ± 0.00\n",
      "Eval after update 20: mean reward 0.00 ± 0.00\n",
      "Eval after update 30: mean reward 0.00 ± 0.00\n",
      "Eval after update 40: mean reward 0.00 ± 0.00\n",
      "Eval after update 50: mean reward 0.00 ± 0.00\n",
      "Eval after update 60: mean reward 0.00 ± 0.00\n",
      "Eval after update 70: mean reward 0.00 ± 0.00\n",
      "Eval after update 80: mean reward 0.00 ± 0.00\n",
      "Eval after update 90: mean reward 0.00 ± 0.00\n",
      "Eval after update 100: mean reward 0.00 ± 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 245\u001b[39m\n\u001b[32m    242\u001b[39m         plt.show()\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 225\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;66;03m# --- Periodic Evaluation ---\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m update % config[\u001b[33m\"\u001b[39m\u001b[33meval_freq\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m update == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     mean_reward, std_reward = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_preprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_episodes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m     eval_results.append((global_step, mean_reward, std_reward))\n\u001b[32m    227\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEval after update \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: mean reward \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 106\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(policy, eval_env, preprocessor, num_episodes)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (terminated \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m         logits, _ = \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m         action = torch.argmax(logits, dim=\u001b[32m1\u001b[39m).item()\n\u001b[32m    108\u001b[39m     next_obs, reward, terminated, truncated, _ = eval_env.step(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RL24_25/rl_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RL24_25/rl_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mActorCritic.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     66\u001b[39m     x = x.float() / \u001b[32m255.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshared\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.actor(features), \u001b[38;5;28mself\u001b[39m.critic(features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RL24_25/rl_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RL24_25/rl_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RL24_25/rl_env/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RL24_25/rl_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RL24_25/rl_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RL24_25/rl_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RL24_25/rl_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ======================\n",
    "# Preprocessing (Frame Stack + Grayscale + Resize)\n",
    "# ======================\n",
    "class Preprocessor:\n",
    "    def __init__(self, frame_stack=4):\n",
    "        self.frame_stack = frame_stack\n",
    "        self.frames = deque(maxlen=frame_stack)\n",
    "        \n",
    "    def reset(self, obs):\n",
    "        processed = self._preprocess(obs)\n",
    "        for _ in range(self.frame_stack):\n",
    "            self.frames.append(processed)\n",
    "        return np.stack(self.frames, axis=0)\n",
    "    \n",
    "    def step(self, obs):\n",
    "        processed = self._preprocess(obs)\n",
    "        self.frames.append(processed)\n",
    "        return np.stack(self.frames, axis=0)\n",
    "    \n",
    "    def _preprocess(self, obs):\n",
    "        gray = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
    "        resized = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "        return resized.astype(np.uint8)\n",
    "\n",
    "# ======================\n",
    "# PPO Network (Shared)\n",
    "# ======================\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_actions, frame_stack=4):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(frame_stack, 32, 8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.actor = nn.Linear(512, num_actions)\n",
    "        self.critic = nn.Linear(512, 1)\n",
    "        # Weight init\n",
    "        for layer in self.shared:\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                nn.init.orthogonal_(layer.weight, np.sqrt(2))\n",
    "                nn.init.constant_(layer.bias, 0.0)\n",
    "        nn.init.orthogonal_(self.actor.weight, 0.01)\n",
    "        nn.init.constant_(self.actor.bias, 0.0)\n",
    "        nn.init.orthogonal_(self.critic.weight, 1.0)\n",
    "        nn.init.constant_(self.critic.bias, 0.0)\n",
    "    def forward(self, x):\n",
    "        x = x.float() / 255.0\n",
    "        features = self.shared(x)\n",
    "        return self.actor(features), self.critic(features)\n",
    "\n",
    "# ======================\n",
    "# Hyperparameters\n",
    "# ======================\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = {\n",
    "    \"num_envs\": 1,            # For demo, set to 1. For speed, use >1 with gym.vector\n",
    "    \"num_steps\": 128,\n",
    "    \"gamma\": 0.99,\n",
    "    \"gae_lambda\": 0.95,\n",
    "    \"num_minibatches\": 4,\n",
    "    \"clip_eps\": 0.1,\n",
    "    \"num_epochs\": 4,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"vf_coef\": 0.5,\n",
    "    \"max_grad_norm\": 0.5,\n",
    "    \"lr\": 2.5e-4,\n",
    "    \"frame_stack\": 4,\n",
    "    \"total_timesteps\": 100_000,\n",
    "    \"eval_freq\": 10,         # Evaluate every 10 updates\n",
    "    \"eval_episodes\": 10\n",
    "}\n",
    "\n",
    "# ======================\n",
    "# Evaluation Function\n",
    "# ======================\n",
    "def evaluate(policy, eval_env, preprocessor, num_episodes=10):\n",
    "    policy.eval()\n",
    "    rewards = []\n",
    "    for _ in range(num_episodes):\n",
    "        obs, _ = eval_env.reset()\n",
    "        state = preprocessor.reset(obs)\n",
    "        episode_reward = 0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        while not (terminated or truncated):\n",
    "            with torch.no_grad():\n",
    "                logits, _ = policy(torch.tensor(state).unsqueeze(0).to(DEVICE))\n",
    "                action = torch.argmax(logits, dim=1).item()\n",
    "            next_obs, reward, terminated, truncated, _ = eval_env.step(action)\n",
    "            state = preprocessor.step(next_obs)\n",
    "            episode_reward += reward\n",
    "        rewards.append(episode_reward)\n",
    "    policy.train()\n",
    "    return np.mean(rewards), np.std(rewards)\n",
    "\n",
    "# ======================\n",
    "# Training Loop\n",
    "# ======================\n",
    "def train():\n",
    "    # Environment setup\n",
    "    env = gym.make(\"ALE/Bowling-v5\", render_mode=None)\n",
    "    eval_env = gym.make(\"ALE/Bowling-v5\", render_mode=None)\n",
    "    preprocessor = Preprocessor(frame_stack=config[\"frame_stack\"])\n",
    "    eval_preprocessor = Preprocessor(frame_stack=config[\"frame_stack\"])\n",
    "    model = ActorCritic(env.action_space.n, config[\"frame_stack\"]).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"], eps=1e-5)\n",
    "    \n",
    "    obs_storage = torch.zeros((config[\"num_steps\"], config[\"num_envs\"], config[\"frame_stack\"], 84, 84), dtype=torch.uint8)\n",
    "    actions_storage = torch.zeros((config[\"num_steps\"], config[\"num_envs\"]), dtype=torch.int64)\n",
    "    logprobs_storage = torch.zeros((config[\"num_steps\"], config[\"num_envs\"]))\n",
    "    rewards_storage = torch.zeros((config[\"num_steps\"], config[\"num_envs\"]))\n",
    "    dones_storage = torch.zeros((config[\"num_steps\"], config[\"num_envs\"]))\n",
    "    values_storage = torch.zeros((config[\"num_steps\"], config[\"num_envs\"]))\n",
    "\n",
    "    eval_results = []\n",
    "\n",
    "    obs, _ = env.reset(seed=42)\n",
    "    state = preprocessor.reset(obs)\n",
    "    done = False\n",
    "\n",
    "    global_step = 0\n",
    "    num_updates = config[\"total_timesteps\"] // (config[\"num_steps\"] * config[\"num_envs\"])\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    for update in range(1, num_updates + 1):\n",
    "        for step in range(config[\"num_steps\"]):\n",
    "            global_step += 1\n",
    "            obs_storage[step, 0] = torch.tensor(state)\n",
    "            dones_storage[step, 0] = float(done)\n",
    "            with torch.no_grad():\n",
    "                logits, value = model(torch.tensor(state).unsqueeze(0).to(DEVICE))\n",
    "                dist = Categorical(logits=logits)\n",
    "                action = dist.sample()\n",
    "                logprob = dist.log_prob(action)\n",
    "            actions_storage[step, 0] = action.item()\n",
    "            logprobs_storage[step, 0] = logprob.item()\n",
    "            values_storage[step, 0] = value.item()\n",
    "            next_obs, reward, terminated, truncated, _ = env.step(action.item())\n",
    "            rewards_storage[step, 0] = reward\n",
    "            done = terminated or truncated\n",
    "            state = preprocessor.step(next_obs)\n",
    "            if done:\n",
    "                next_obs, _ = env.reset()\n",
    "                state = preprocessor.reset(next_obs)\n",
    "                done = False\n",
    "\n",
    "        # --- Learning Phase ---\n",
    "        with torch.no_grad():\n",
    "            _, next_value = model(torch.tensor(state).unsqueeze(0).to(DEVICE))\n",
    "            next_value = next_value.item()\n",
    "            advantages = torch.zeros_like(rewards_storage)\n",
    "            lastgaelam = 0\n",
    "            for t in reversed(range(config[\"num_steps\"])):\n",
    "                if t == config[\"num_steps\"] - 1:\n",
    "                    nextnonterminal = 1.0 - done\n",
    "                    nextvalues = next_value\n",
    "                else:\n",
    "                    nextnonterminal = 1.0 - dones_storage[t + 1, 0]\n",
    "                    nextvalues = values_storage[t + 1, 0]\n",
    "                delta = rewards_storage[t, 0] + config[\"gamma\"] * nextvalues * nextnonterminal - values_storage[t, 0]\n",
    "                advantages[t, 0] = lastgaelam = delta + config[\"gamma\"] * config[\"gae_lambda\"] * nextnonterminal * lastgaelam\n",
    "            returns = advantages + values_storage\n",
    "\n",
    "        # Flatten the batch for training\n",
    "        b_obs = obs_storage.reshape((-1, config[\"frame_stack\"], 84, 84)).float().to(DEVICE)\n",
    "        b_logprobs = logprobs_storage.reshape(-1).to(DEVICE)\n",
    "        b_actions = actions_storage.reshape(-1).to(DEVICE)\n",
    "        b_advantages = advantages.reshape(-1).to(DEVICE)\n",
    "        b_returns = returns.reshape(-1).to(DEVICE)\n",
    "        b_values = values_storage.reshape(-1).to(DEVICE)\n",
    "\n",
    "        # Normalize advantages\n",
    "        b_advantages = (b_advantages - b_advantages.mean()) / (b_advantages.std() + 1e-8)\n",
    "\n",
    "        # Optimize policy and value networks\n",
    "        inds = np.arange(config[\"num_steps\"] * config[\"num_envs\"])\n",
    "        for epoch in range(config[\"num_epochs\"]):\n",
    "            np.random.shuffle(inds)\n",
    "            for start in range(0, len(inds), len(inds) // config[\"num_minibatches\"]):\n",
    "                end = start + len(inds) // config[\"num_minibatches\"]\n",
    "                mb_inds = inds[start:end]\n",
    "                logits, value = model(b_obs[mb_inds])\n",
    "                dist = Categorical(logits=logits)\n",
    "                newlogprob = dist.log_prob(b_actions[mb_inds])\n",
    "                entropy = dist.entropy().mean()\n",
    "                ratio = (newlogprob - b_logprobs[mb_inds]).exp()\n",
    "                pg_loss1 = -b_advantages[mb_inds] * ratio\n",
    "                pg_loss2 = -b_advantages[mb_inds] * torch.clamp(ratio, 1 - config[\"clip_eps\"], 1 + config[\"clip_eps\"])\n",
    "                pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "                v_loss_unclipped = (value.squeeze() - b_returns[mb_inds]) ** 2\n",
    "                v_clipped = b_values[mb_inds] + torch.clamp(\n",
    "                    value.squeeze() - b_values[mb_inds],\n",
    "                    -config[\"clip_eps\"],\n",
    "                    config[\"clip_eps\"]\n",
    "                )\n",
    "                v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n",
    "                v_loss = 0.5 * torch.max(v_loss_unclipped, v_loss_clipped).mean()\n",
    "                loss = pg_loss - config[\"ent_coef\"] * entropy + config[\"vf_coef\"] * v_loss\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), config[\"max_grad_norm\"])\n",
    "                optimizer.step()\n",
    "\n",
    "        # --- Periodic Evaluation ---\n",
    "        if update % config[\"eval_freq\"] == 0 or update == 1:\n",
    "            mean_reward, std_reward = evaluate(model, eval_env, eval_preprocessor, num_episodes=config[\"eval_episodes\"])\n",
    "            eval_results.append((global_step, mean_reward, std_reward))\n",
    "            print(f\"Eval after update {update}: mean reward {mean_reward:.2f} ± {std_reward:.2f}\")\n",
    "\n",
    "    env.close()\n",
    "    eval_env.close()\n",
    "\n",
    "    # --- Visualization ---\n",
    "    if len(eval_results) > 0:\n",
    "        steps, means, stds = zip(*eval_results)\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.errorbar(steps, means, yerr=stds, fmt='-o', capsize=5)\n",
    "        plt.title(\"Evaluation Performance During Training\")\n",
    "        plt.xlabel(\"Training Steps\")\n",
    "        plt.ylabel(\"Mean Reward ± SD\")\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"ppo_eval_curve.png\")\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df0b862",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval after update 0: mean reward -1207.83 ± 341.35\n",
      "Eval after update 10: mean reward -1293.99 ± 258.64\n",
      "Eval after update 20: mean reward -1211.40 ± 78.98\n",
      "Eval after update 30: mean reward -1303.66 ± 246.18\n",
      "Eval after update 40: mean reward -1244.04 ± 240.97\n",
      "Eval after update 50: mean reward -1118.30 ± 223.26\n",
      "Eval after update 60: mean reward -1073.45 ± 341.78\n",
      "Eval after update 70: mean reward -1149.77 ± 199.27\n",
      "Eval after update 80: mean reward -1182.68 ± 283.24\n",
      "Eval after update 90: mean reward -823.24 ± 102.93\n",
      "Eval after update 100: mean reward -1155.12 ± 58.24\n",
      "Eval after update 110: mean reward -1155.54 ± 244.74\n",
      "Eval after update 120: mean reward -1287.54 ± 258.81\n",
      "Eval after update 130: mean reward -1070.28 ± 199.89\n",
      "Eval after update 140: mean reward -998.61 ± 190.33\n",
      "Eval after update 150: mean reward -1072.27 ± 101.07\n",
      "Eval after update 160: mean reward -864.58 ± 320.85\n",
      "Eval after update 170: mean reward -1060.37 ± 234.78\n",
      "Eval after update 180: mean reward -1135.97 ± 290.92\n",
      "Eval after update 190: mean reward -1108.12 ± 277.52\n",
      "Eval after update 200: mean reward -915.45 ± 189.41\n",
      "Eval after update 210: mean reward -964.65 ± 355.60\n",
      "Eval after update 220: mean reward -950.96 ± 150.66\n",
      "Eval after update 230: mean reward -902.72 ± 81.75\n",
      "Eval after update 240: mean reward -977.06 ± 118.05\n",
      "Eval after update 250: mean reward -1151.29 ± 117.61\n",
      "Eval after update 260: mean reward -1065.30 ± 329.33\n",
      "Eval after update 270: mean reward -974.74 ± 211.27\n",
      "Eval after update 280: mean reward -896.14 ± 154.51\n",
      "Eval after update 290: mean reward -1049.87 ± 327.36\n",
      "Eval after update 300: mean reward -989.34 ± 327.99\n",
      "Eval after update 310: mean reward -849.31 ± 112.41\n",
      "Eval after update 320: mean reward -803.90 ± 326.72\n",
      "Eval after update 330: mean reward -1144.36 ± 107.42\n",
      "Eval after update 340: mean reward -979.77 ± 230.81\n",
      "Eval after update 350: mean reward -877.55 ± 90.77\n",
      "Eval after update 360: mean reward -904.47 ± 337.26\n",
      "Eval after update 370: mean reward -1096.83 ± 239.66\n",
      "Eval after update 380: mean reward -983.18 ± 267.36\n",
      "Eval after update 390: mean reward -988.69 ± 283.32\n",
      "Eval after update 400: mean reward -1102.75 ± 183.51\n",
      "Eval after update 410: mean reward -1017.09 ± 298.92\n",
      "Eval after update 420: mean reward -1034.90 ± 217.92\n",
      "Eval after update 430: mean reward -1021.66 ± 251.63\n",
      "Eval after update 440: mean reward -886.84 ± 297.44\n",
      "Eval after update 450: mean reward -975.08 ± 199.26\n",
      "Eval after update 460: mean reward -767.61 ± 129.81\n",
      "Eval after update 470: mean reward -950.67 ± 134.79\n",
      "Eval after update 480: mean reward -740.63 ± 194.57\n",
      "Eval after update 490: mean reward -1218.53 ± 365.93\n",
      "Eval after update 500: mean reward -1068.74 ± 166.31\n",
      "Eval after update 510: mean reward -871.97 ± 127.06\n",
      "Eval after update 520: mean reward -770.33 ± 142.70\n",
      "Eval after update 530: mean reward -775.96 ± 99.40\n",
      "Eval after update 540: mean reward -1008.59 ± 450.10\n",
      "Eval after update 550: mean reward -810.50 ± 131.41\n",
      "Eval after update 560: mean reward -822.55 ± 366.12\n",
      "Eval after update 570: mean reward -877.78 ± 205.31\n",
      "Eval after update 580: mean reward -965.51 ± 173.33\n",
      "Eval after update 590: mean reward -689.06 ± 118.36\n",
      "Eval after update 600: mean reward -587.43 ± 200.06\n",
      "Eval after update 610: mean reward -815.96 ± 102.74\n",
      "Eval after update 620: mean reward -849.88 ± 147.28\n",
      "Eval after update 630: mean reward -828.44 ± 151.70\n",
      "Eval after update 640: mean reward -821.25 ± 54.03\n",
      "Eval after update 650: mean reward -808.69 ± 221.26\n",
      "Eval after update 660: mean reward -738.36 ± 80.15\n",
      "Eval after update 670: mean reward -792.99 ± 221.38\n",
      "Eval after update 680: mean reward -583.28 ± 174.89\n",
      "Eval after update 690: mean reward -710.06 ± 178.68\n",
      "Eval after update 700: mean reward -909.59 ± 243.30\n",
      "Eval after update 710: mean reward -594.21 ± 128.97\n",
      "Eval after update 720: mean reward -824.27 ± 161.65\n",
      "Eval after update 730: mean reward -742.50 ± 183.20\n",
      "Eval after update 740: mean reward -716.11 ± 156.26\n",
      "Eval after update 750: mean reward -803.69 ± 123.36\n",
      "Eval after update 760: mean reward -978.50 ± 123.40\n",
      "Eval after update 770: mean reward -985.51 ± 170.11\n",
      "Eval after update 780: mean reward -798.10 ± 38.40\n",
      "Eval after update 790: mean reward -1042.87 ± 201.18\n",
      "Eval after update 800: mean reward -910.45 ± 55.10\n",
      "Eval after update 810: mean reward -907.03 ± 83.56\n",
      "Eval after update 820: mean reward -834.00 ± 65.02\n",
      "Eval after update 830: mean reward -830.91 ± 184.79\n",
      "Eval after update 840: mean reward -709.27 ± 58.13\n",
      "Eval after update 850: mean reward -910.54 ± 167.27\n",
      "Eval after update 860: mean reward -956.38 ± 219.38\n",
      "Eval after update 870: mean reward -839.78 ± 185.21\n",
      "Eval after update 880: mean reward -926.78 ± 137.43\n",
      "Eval after update 890: mean reward -799.06 ± 122.40\n",
      "Eval after update 900: mean reward -755.99 ± 165.48\n",
      "Eval after update 910: mean reward -911.15 ± 58.86\n",
      "Eval after update 920: mean reward -1025.68 ± 50.31\n",
      "Eval after update 930: mean reward -823.19 ± 49.82\n",
      "Eval after update 940: mean reward -993.62 ± 277.23\n",
      "Eval after update 950: mean reward -968.16 ± 79.95\n",
      "Eval after update 960: mean reward -1021.71 ± 191.46\n",
      "Eval after update 970: mean reward -745.90 ± 58.13\n",
      "Eval after update 980: mean reward -736.51 ± 69.44\n",
      "Eval after update 990: mean reward -1108.71 ± 214.10\n",
      "Eval after update 1000: mean reward -1030.62 ± 161.13\n",
      "Eval after update 1010: mean reward -1069.82 ± 121.12\n",
      "Eval after update 1020: mean reward -954.42 ± 132.04\n",
      "Eval after update 1030: mean reward -956.19 ± 62.35\n",
      "Eval after update 1040: mean reward -925.95 ± 101.27\n",
      "Eval after update 1050: mean reward -789.50 ± 20.13\n",
      "Eval after update 1060: mean reward -835.06 ± 61.17\n",
      "Eval after update 1070: mean reward -746.81 ± 44.14\n",
      "Eval after update 1080: mean reward -623.55 ± 104.24\n",
      "Eval after update 1090: mean reward -714.11 ± 70.44\n",
      "Eval after update 1100: mean reward -723.76 ± 126.34\n",
      "Eval after update 1110: mean reward -742.13 ± 116.54\n",
      "Eval after update 1120: mean reward -687.54 ± 49.71\n",
      "Eval after update 1130: mean reward -759.57 ± 117.05\n",
      "Eval after update 1140: mean reward -975.06 ± 230.35\n",
      "Eval after update 1150: mean reward -689.42 ± 133.03\n",
      "Eval after update 1160: mean reward -1132.04 ± 185.86\n",
      "Eval after update 1170: mean reward -1055.25 ± 257.63\n",
      "Eval after update 1180: mean reward -1048.88 ± 144.79\n",
      "Eval after update 1190: mean reward -867.47 ± 49.16\n",
      "Eval after update 1200: mean reward -928.39 ± 41.61\n",
      "Eval after update 1210: mean reward -996.29 ± 89.66\n",
      "Eval after update 1220: mean reward -944.97 ± 128.74\n",
      "Eval after update 1230: mean reward -888.46 ± 135.79\n",
      "Eval after update 1240: mean reward -882.44 ± 113.38\n",
      "Eval after update 1250: mean reward -641.56 ± 104.05\n",
      "Eval after update 1260: mean reward -860.46 ± 52.98\n",
      "Eval after update 1270: mean reward -1084.07 ± 213.02\n",
      "Eval after update 1280: mean reward -1088.45 ± 172.69\n",
      "Eval after update 1290: mean reward -1069.58 ± 125.96\n",
      "Eval after update 1300: mean reward -1130.19 ± 251.39\n",
      "Eval after update 1310: mean reward -1041.15 ± 172.24\n",
      "Eval after update 1320: mean reward -941.88 ± 41.31\n",
      "Eval after update 1330: mean reward -1044.25 ± 265.74\n",
      "Eval after update 1340: mean reward -894.77 ± 135.64\n",
      "Eval after update 1350: mean reward -861.77 ± 74.56\n",
      "Eval after update 1360: mean reward -793.78 ± 53.32\n",
      "Eval after update 1370: mean reward -715.46 ± 101.86\n",
      "Eval after update 1380: mean reward -572.45 ± 104.15\n",
      "Eval after update 1390: mean reward -1098.08 ± 44.46\n",
      "Eval after update 1400: mean reward -1116.14 ± 56.28\n",
      "Eval after update 1410: mean reward -1114.02 ± 94.95\n",
      "Eval after update 1420: mean reward -987.41 ± 134.84\n",
      "Eval after update 1430: mean reward -929.77 ± 67.91\n",
      "Eval after update 1440: mean reward -935.40 ± 11.61\n",
      "Eval after update 1450: mean reward -1024.80 ± 189.15\n",
      "Eval after update 1460: mean reward -971.44 ± 140.52\n",
      "Eval after update 1470: mean reward -936.02 ± 96.99\n",
      "Eval after update 1480: mean reward -883.60 ± 85.38\n",
      "Eval after update 1490: mean reward -903.13 ± 53.86\n",
      "Eval after update 1500: mean reward -860.03 ± 97.11\n",
      "Eval after update 1510: mean reward -755.71 ± 52.86\n",
      "Eval after update 1520: mean reward -622.56 ± 51.65\n",
      "Eval after update 1530: mean reward -736.16 ± 138.05\n",
      "Eval after update 1540: mean reward -1048.84 ± 165.76\n",
      "Eval after update 1550: mean reward -1094.02 ± 244.40\n",
      "Eval after update 1560: mean reward -962.59 ± 207.42\n",
      "Eval after update 1570: mean reward -801.59 ± 34.25\n",
      "Eval after update 1580: mean reward -854.50 ± 54.93\n",
      "Eval after update 1590: mean reward -796.32 ± 5.08\n",
      "Eval after update 1600: mean reward -983.78 ± 161.31\n",
      "Eval after update 1610: mean reward -987.61 ± 271.87\n",
      "Eval after update 1620: mean reward -723.81 ± 43.18\n",
      "Eval after update 1630: mean reward -799.02 ± 62.79\n",
      "Eval after update 1640: mean reward -912.52 ± 249.14\n",
      "Eval after update 1650: mean reward -677.52 ± 95.02\n",
      "Eval after update 1660: mean reward -1253.43 ± 14.58\n",
      "Eval after update 1670: mean reward -1267.09 ± 148.74\n",
      "Eval after update 1680: mean reward -1248.76 ± 131.54\n",
      "Eval after update 1690: mean reward -1088.78 ± 75.02\n",
      "Eval after update 1700: mean reward -1015.46 ± 158.73\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym  # Using gymnasium instead of gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Policy Network \n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.mean = nn.Linear(256, act_dim)\n",
    "        self.log_std = nn.Parameter(torch.zeros(act_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return self.mean(x), self.log_std.exp()\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        mean, std = self.forward(obs)\n",
    "        dist = torch.distributions.Normal(mean, std)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action).sum(axis=-1)\n",
    "        return action, log_prob\n",
    "\n",
    "# Value Network \n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, obs_dim):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x).squeeze(-1)\n",
    "\n",
    "# PPO Agent \n",
    "class PPOAgent:\n",
    "    def __init__(self, obs_dim, act_dim, lr=1e-4, gamma=0.95, clip_eps=0.1, ent_coef=0.01):\n",
    "        self.policy = PolicyNetwork(obs_dim, act_dim)\n",
    "        self.value = ValueNetwork(obs_dim)\n",
    "        self.policy_optimizer = optim.Adam(self.policy.parameters(), lr=lr)\n",
    "        self.value_optimizer = optim.Adam(self.value.parameters(), lr=lr)\n",
    "        self.gamma = gamma\n",
    "        self.clip_eps = clip_eps\n",
    "        self.ent_coef = ent_coef\n",
    "        self.obs_mean = torch.zeros(obs_dim)\n",
    "        self.obs_std = torch.ones(obs_dim)\n",
    "\n",
    "    def compute_advantages(self, rewards, values, dones, next_value):\n",
    "        advantages = []\n",
    "        gae = 0\n",
    "        for step in reversed(range(len(rewards))):\n",
    "            gae_lambda = 0.92  # Fix typo in variable name\n",
    "            delta = rewards[step] + self.gamma * (1 - dones[step]) * next_value - values[step]\n",
    "            gae = delta + self.gamma * gae_lambda * (1 - dones[step]) * gae\n",
    "            advantages.insert(0, gae)\n",
    "            next_value = values[step]\n",
    "        # Normalize AFTER the loop\n",
    "        advantages = (np.array(advantages) - np.mean(advantages)) / (np.std(advantages) + 1e-8)\n",
    "        return advantages\n",
    "\n",
    "\n",
    "    def update(self, obs, actions, log_probs_old, returns, advantages):\n",
    "        obs = (torch.tensor(obs, dtype=torch.float32) - self.obs_mean) / (self.obs_std + 1e-8)\n",
    "        actions = torch.tensor(actions, dtype=torch.float32)\n",
    "        log_probs_old = torch.tensor(log_probs_old, dtype=torch.float32)\n",
    "        returns = torch.tensor(returns, dtype=torch.float32)\n",
    "        advantages = torch.tensor(advantages, dtype=torch.float32)\n",
    "\n",
    "        # Policy update\n",
    "        mean, std = self.policy(obs)\n",
    "        dist = torch.distributions.Normal(mean, std)\n",
    "        log_probs = dist.log_prob(actions).sum(axis=-1)\n",
    "        ratio = (log_probs - log_probs_old).exp()\n",
    "        clipped_ratio = torch.clamp(ratio, 1 - self.clip_eps, 1 + self.clip_eps)\n",
    "        policy_loss = -torch.min(ratio * advantages, clipped_ratio * advantages).mean()\n",
    "\n",
    "        # Add entropy bonus\n",
    "        entropy = dist.entropy().mean()\n",
    "        policy_loss -= self.ent_coef * entropy  # <--- Add this line\n",
    "\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.policy.parameters(), 0.5)  # Clip gradients\n",
    "        self.policy_optimizer.step()\n",
    "\n",
    "        # Value update\n",
    "        values = self.value(obs)\n",
    "        value_loss = nn.MSELoss()(values, returns)\n",
    "        self.value_optimizer.zero_grad()\n",
    "        value_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.value.parameters(), 0.5)  # Clip gradients\n",
    "        self.value_optimizer.step()\n",
    "\n",
    "    def update_normalization(self, obs_buffer):\n",
    "        obs_tensor = torch.tensor(obs_buffer, dtype=torch.float32)\n",
    "        batch_mean = torch.mean(obs_tensor, dim=0)\n",
    "        batch_std = torch.std(obs_tensor, dim=0)\n",
    "    \n",
    "        # Update running averages (0.9 momentum)\n",
    "        self.obs_mean = 0.9 * self.obs_mean + 0.1 * batch_mean\n",
    "        self.obs_std = 0.9 * self.obs_std + 0.1 * batch_std + 1e-8\n",
    "\n",
    "\n",
    "# Corrected Training Loop\n",
    "def train(env_name, total_timesteps=100000):\n",
    "    env = gym.make(env_name)\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "    agent = PPOAgent(obs_dim, act_dim)\n",
    "    obs, _ = env.reset()  \n",
    "    episode_rewards = []\n",
    "    \n",
    "    for update in range(2000):\n",
    "        obs_buffer, act_buffer, logp_buffer, rew_buffer, val_buffer, done_buffer = [], [], [], [], [], []\n",
    "        \n",
    "        for t in range(4096):\n",
    "            # Normalize observation before action selection\n",
    "            obs_tensor = torch.tensor(obs, dtype=torch.float32)\n",
    "            normalized_obs = (obs_tensor - agent.obs_mean) / (agent.obs_std + 1e-8)\n",
    "            action, log_prob = agent.policy.get_action(normalized_obs)\n",
    "            \n",
    "            value = agent.value(normalized_obs).item()  # Also normalize for value\n",
    "            \n",
    "            next_obs, reward, terminated, truncated, info = env.step(action.detach().numpy())\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            # Store transitions WITH SCALED REWARD\n",
    "            obs_buffer.append(obs)\n",
    "            act_buffer.append(action.detach().numpy())\n",
    "            logp_buffer.append(log_prob.item())\n",
    "            rew_buffer.append(reward / 16.0)  # Scaled reward\n",
    "            val_buffer.append(value)\n",
    "            done_buffer.append(done)\n",
    "            obs = next_obs\n",
    "            \n",
    "            if done:\n",
    "                obs, _ = env.reset()\n",
    "\n",
    "        agent.update_normalization(obs_buffer)  # Update stats after batch\n",
    "\n",
    "        # Compute returns and advantages\n",
    "        next_value = agent.value(\n",
    "            (torch.tensor(obs, dtype=torch.float32) - agent.obs_mean) / (agent.obs_std + 1e-8)\n",
    "        ).item()\n",
    "        advantages = agent.compute_advantages(rew_buffer, val_buffer, done_buffer, next_value)\n",
    "        returns = np.array(val_buffer) + np.array(advantages)\n",
    "        agent.update(obs_buffer, act_buffer, logp_buffer, returns, advantages)\n",
    "        \n",
    "        # Evaluation (with normalization)\n",
    "        if update % 10 == 0:\n",
    "            eval_rewards = []\n",
    "            for _ in range(5):\n",
    "                eval_obs, _ = env.reset()  \n",
    "                total_reward = 0\n",
    "                done = False\n",
    "                while not done:\n",
    "                    # Normalize eval observation\n",
    "                    norm_eval_obs = (torch.tensor(eval_obs, dtype=torch.float32) - agent.obs_mean) / (agent.obs_std + 1e-8)\n",
    "                    action, _ = agent.policy.get_action(norm_eval_obs)\n",
    "                    eval_obs, reward, terminated, truncated, _ = env.step(action.detach().numpy())\n",
    "                    done = terminated or truncated\n",
    "                    total_reward += reward\n",
    "                eval_rewards.append(total_reward)\n",
    "            print(f\"Eval after update {update}: mean reward {np.mean(eval_rewards):.2f} ± {np.std(eval_rewards):.2f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train(\"Pendulum-v1\")  # Works with Gymnasium's Pendulum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3bb28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
